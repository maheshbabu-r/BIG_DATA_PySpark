{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spark_ENV.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaiciVdNQsIF",
        "outputId": "ab257278-1c01-4e21-d44c-8c043a33a422"
      },
      "source": [
        "!pwd\n",
        "!ls\n",
        "!python --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "sample_data\n",
            "Python 3.7.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmhtCBk9Qxpl",
        "outputId": "bfe9bb9b-feaf-4238-f044-be488bf70799"
      },
      "source": [
        "!wget https://mirrors.estointernet.in/apache/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2.tgz\n",
        "!tar -xvzf spark-3.1.2-bin-hadoop3.2.tgz\n",
        "!pip install findspark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-07 03:19:59--  https://mirrors.estointernet.in/apache/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2.tgz\n",
            "Resolving mirrors.estointernet.in (mirrors.estointernet.in)... 43.255.166.254, 2403:8940:3:1::f\n",
            "Connecting to mirrors.estointernet.in (mirrors.estointernet.in)|43.255.166.254|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 228834641 (218M) [application/octet-stream]\n",
            "Saving to: ‘spark-3.1.2-bin-hadoop3.2.tgz’\n",
            "\n",
            "spark-3.1.2-bin-had 100%[===================>] 218.23M  10.8MB/s    in 21s     \n",
            "\n",
            "2021-09-07 03:20:21 (10.6 MB/s) - ‘spark-3.1.2-bin-hadoop3.2.tgz’ saved [228834641/228834641]\n",
            "\n",
            "spark-3.1.2-bin-hadoop3.2/\n",
            "spark-3.1.2-bin-hadoop3.2/R/\n",
            "spark-3.1.2-bin-hadoop3.2/R/lib/\n",
            "spark-3.1.2-bin-hadoop3.2/R/lib/sparkr.zip\n",
            "spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/\n",
            "spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/worker/\n",
            "spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/worker/worker.R\n",
            "spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/worker/daemon.R\n",
            "spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/tests/\n",
            "spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/tests/testthat/\n",
            "spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/tests/testthat/test_basic.R\n",
            "spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/profile/\n",
            "spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/profile/shell.R\n",
            "spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/profile/general.R\n",
            "spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/doc/\n",
            "spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/doc/sparkr-vignettes.html\n",
            "spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/doc/sparkr-vignettes.Rmd\n",
            "spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/doc/sparkr-vignettes.R\n",
            "spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/doc/index.html\n",
            "spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/R/\n",
            "spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/R/SparkR\n",
            "spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/R/SparkR.rdx\n",
            "spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/R/SparkR.rdb\n",
            "spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/Meta/\n",
            "spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/Meta/features.rds\n",
            "spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/Meta/package.rds\n",
            "spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/Meta/nsInfo.rds\n",
            "spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/Meta/vignette.rds\n",
            "spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/Meta/Rd.rds\n",
            "spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/Meta/links.rds\n",
            "spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/Meta/hsearch.rds\n",
            "spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/DESCRIPTION\n",
            "spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/NAMESPACE\n",
            "spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/html/\n",
            "spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/html/R.css\n",
            "spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/html/00Index.html\n",
            "spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/INDEX\n",
            "spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/help/\n",
            "spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/help/aliases.rds\n",
            "spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/help/AnIndex\n",
            "spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/help/SparkR.rdx\n",
            "spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/help/SparkR.rdb\n",
            "spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/help/paths.rds\n",
            "spark-3.1.2-bin-hadoop3.2/sbin/\n",
            "spark-3.1.2-bin-hadoop3.2/sbin/workers.sh\n",
            "spark-3.1.2-bin-hadoop3.2/sbin/stop-workers.sh\n",
            "spark-3.1.2-bin-hadoop3.2/sbin/stop-worker.sh\n",
            "spark-3.1.2-bin-hadoop3.2/sbin/stop-thriftserver.sh\n",
            "spark-3.1.2-bin-hadoop3.2/sbin/stop-slaves.sh\n",
            "spark-3.1.2-bin-hadoop3.2/sbin/stop-slave.sh\n",
            "spark-3.1.2-bin-hadoop3.2/sbin/stop-mesos-shuffle-service.sh\n",
            "spark-3.1.2-bin-hadoop3.2/sbin/stop-mesos-dispatcher.sh\n",
            "spark-3.1.2-bin-hadoop3.2/sbin/stop-master.sh\n",
            "spark-3.1.2-bin-hadoop3.2/sbin/stop-history-server.sh\n",
            "spark-3.1.2-bin-hadoop3.2/sbin/stop-all.sh\n",
            "spark-3.1.2-bin-hadoop3.2/sbin/start-workers.sh\n",
            "spark-3.1.2-bin-hadoop3.2/sbin/start-worker.sh\n",
            "spark-3.1.2-bin-hadoop3.2/sbin/start-thriftserver.sh\n",
            "spark-3.1.2-bin-hadoop3.2/sbin/start-slaves.sh\n",
            "spark-3.1.2-bin-hadoop3.2/sbin/start-slave.sh\n",
            "spark-3.1.2-bin-hadoop3.2/sbin/start-mesos-shuffle-service.sh\n",
            "spark-3.1.2-bin-hadoop3.2/sbin/start-mesos-dispatcher.sh\n",
            "spark-3.1.2-bin-hadoop3.2/sbin/start-master.sh\n",
            "spark-3.1.2-bin-hadoop3.2/sbin/start-history-server.sh\n",
            "spark-3.1.2-bin-hadoop3.2/sbin/start-all.sh\n",
            "spark-3.1.2-bin-hadoop3.2/sbin/spark-daemons.sh\n",
            "spark-3.1.2-bin-hadoop3.2/sbin/spark-daemon.sh\n",
            "spark-3.1.2-bin-hadoop3.2/sbin/slaves.sh\n",
            "spark-3.1.2-bin-hadoop3.2/sbin/decommission-worker.sh\n",
            "spark-3.1.2-bin-hadoop3.2/sbin/decommission-slave.sh\n",
            "spark-3.1.2-bin-hadoop3.2/sbin/spark-config.sh\n",
            "spark-3.1.2-bin-hadoop3.2/python/\n",
            "spark-3.1.2-bin-hadoop3.2/python/dist/\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark.egg-info/\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark.egg-info/SOURCES.txt\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark.egg-info/top_level.txt\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark.egg-info/requires.txt\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark.egg-info/dependency_links.txt\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark.egg-info/PKG-INFO\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/python/\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/python/pyspark/\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/python/pyspark/shell.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/__pycache__/\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/__pycache__/install.cpython-38.pyc\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/evaluation.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/common.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/common.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/clustering.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/classification.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/_typing.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/__init__.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/util.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/util.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/tree.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/tree.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/tests/\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/tests/test_util.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/tests/test_streaming_algorithms.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/tests/test_stat.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/tests/test_feature.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/tests/test_algorithms.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/tests/__init__.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/tests/test_linalg.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/regression.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/clustering.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/classification.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/stat/\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/stat/_statistics.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/stat/__init__.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/stat/__init__.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/stat/KernelDensity.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/stat/KernelDensity.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/stat/test.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/stat/test.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/stat/distribution.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/stat/distribution.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/stat/_statistics.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/regression.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/recommendation.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/recommendation.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/random.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/random.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/linalg/\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/linalg/distributed.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/linalg/__init__.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/linalg/__init__.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/linalg/distributed.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/fpm.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/fpm.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/feature.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/feature.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/evaluation.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/wrapper.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/wrapper.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/util.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/util.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/tree.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/tests/\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/tests/test_wrapper.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/tests/test_util.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/tests/test_stat.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/tests/test_pipeline.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/tests/test_persistence.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/tests/test_linalg.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/tests/test_image.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/tests/test_feature.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/tests/test_algorithms.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/tests/__init__.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/tests/test_tuning.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/tests/test_training_summary.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/tests/test_param.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/tests/test_evaluation.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/tests/test_base.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/stat.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/stat.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/regression.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/recommendation.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/pipeline.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/pipeline.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/param/\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/param/shared.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/param/shared.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/param/_shared_params_code_gen.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/param/_shared_params_code_gen.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/param/__init__.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/param/__init__.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/linalg/\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/linalg/__init__.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/linalg/__init__.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/image.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/image.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/functions.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/fpm.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/feature.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/evaluation.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/common.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/common.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/clustering.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/classification.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/base.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/_typing.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/__init__.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/tuning.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/tuning.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/tree.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/regression.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/recommendation.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/functions.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/fpm.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/feature.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/evaluation.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/clustering.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/classification.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/base.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/join.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/java_gateway.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/install.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/find_spark_home.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/files.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/files.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/daemon.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/context.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/context.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/conf.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/conf.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/cloudpickle/\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/cloudpickle/compat.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/cloudpickle/cloudpickle_fast.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/cloudpickle/cloudpickle.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/cloudpickle/__init__.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/broadcast.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/broadcast.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/accumulators.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/accumulators.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/_typing.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/_globals.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/__init__.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/__init__.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/window.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/window.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/utils.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/udf.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/types.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/types.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/tests/\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/tests/test_utils.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/tests/test_udf.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/tests/test_types.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/tests/test_streaming.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/tests/test_session.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/tests/test_serde.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/tests/test_readwriter.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/tests/test_pandas_udf_window.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/tests/test_pandas_udf_typehints.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/tests/test_pandas_udf_scalar.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/tests/test_pandas_udf_grouped_agg.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/tests/test_pandas_udf.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/tests/test_pandas_map.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/tests/test_pandas_cogrouped_map.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/tests/test_datasources.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/tests/test_context.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/tests/test_conf.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/tests/test_catalog.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/tests/__init__.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/tests/test_pandas_grouped_map.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/tests/test_group.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/tests/test_functions.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/tests/test_dataframe.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/tests/test_column.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/tests/test_arrow.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/streaming.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/session.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/readwriter.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/pandas/\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/pandas/utils.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/pandas/typehints.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/pandas/serializers.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/pandas/map_ops.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/pandas/map_ops.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/pandas/group_ops.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/pandas/group_ops.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/pandas/functions.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/pandas/functions.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/pandas/conversion.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/pandas/_typing/\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/pandas/_typing/protocols/\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/pandas/_typing/protocols/series.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/pandas/_typing/protocols/frame.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/pandas/_typing/protocols/__init__.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/pandas/_typing/__init__.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/pandas/__init__.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/pandas/types.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/pandas/conversion.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/group.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/group.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/dataframe.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/context.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/conf.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/conf.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/column.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/catalog.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/avro/\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/avro/__init__.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/avro/functions.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/avro/functions.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/_typing.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/__init__.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/__init__.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/udf.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/streaming.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/session.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/readwriter.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/functions.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/functions.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/dataframe.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/context.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/column.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/catalog.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/shuffle.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/shell.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/serializers.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/resultiterable.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/resultiterable.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/resource/\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/resource/tests/\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/resource/tests/test_resources.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/resource/tests/__init__.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/resource/requests.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/resource/requests.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/resource/information.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/resource/information.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/resource/__init__.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/resource/profile.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/resource/profile.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/rddsampler.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/rdd.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/py.typed\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/profiler.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/profiler.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/worker.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/version.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/taskcontext.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/rdd.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/version.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/util.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/traceback_utils.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/tests/\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/tests/test_worker.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/tests/test_util.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/tests/test_taskcontext.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/tests/test_shuffle.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/tests/test_serializers.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/tests/test_readwrite.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/tests/test_rddbarrier.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/tests/test_rdd.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/tests/test_profiler.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/tests/test_pin_thread.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/tests/test_join.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/tests/test_install_spark.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/tests/test_daemon.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/tests/test_context.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/tests/test_conf.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/tests/test_broadcast.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/tests/test_appsubmit.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/tests/__init__.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/testing/\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/testing/streamingutils.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/testing/sqlutils.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/testing/mlutils.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/testing/mllibutils.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/testing/__init__.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/testing/utils.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/taskcontext.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/streaming/\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/streaming/util.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/streaming/tests/\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/streaming/tests/test_listener.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/streaming/tests/test_kinesis.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/streaming/tests/test_dstream.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/streaming/tests/test_context.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/streaming/tests/__init__.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/streaming/listener.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/streaming/listener.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/streaming/kinesis.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/streaming/kinesis.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/streaming/dstream.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/streaming/context.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/streaming/context.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/streaming/__init__.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/streaming/dstream.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/storagelevel.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/storagelevel.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/status.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/status.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/statcounter.pyi\n",
            "spark-3.1.2-bin-hadoop3.2/python/pyspark/statcounter.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/pylintrc\n",
            "spark-3.1.2-bin-hadoop3.2/python/lib/\n",
            "spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip\n",
            "spark-3.1.2-bin-hadoop3.2/python/lib/PY4J_LICENSE.txt\n",
            "spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip\n",
            "spark-3.1.2-bin-hadoop3.2/python/docs/\n",
            "spark-3.1.2-bin-hadoop3.2/python/docs/source/\n",
            "spark-3.1.2-bin-hadoop3.2/python/docs/source/user_guide/\n",
            "spark-3.1.2-bin-hadoop3.2/python/docs/source/user_guide/python_packaging.rst\n",
            "spark-3.1.2-bin-hadoop3.2/python/docs/source/user_guide/index.rst\n",
            "spark-3.1.2-bin-hadoop3.2/python/docs/source/user_guide/arrow_pandas.rst\n",
            "spark-3.1.2-bin-hadoop3.2/python/docs/source/reference/\n",
            "spark-3.1.2-bin-hadoop3.2/python/docs/source/reference/pyspark.streaming.rst\n",
            "spark-3.1.2-bin-hadoop3.2/python/docs/source/reference/pyspark.ss.rst\n",
            "spark-3.1.2-bin-hadoop3.2/python/docs/source/reference/pyspark.rst\n",
            "spark-3.1.2-bin-hadoop3.2/python/docs/source/reference/pyspark.resource.rst\n",
            "spark-3.1.2-bin-hadoop3.2/python/docs/source/reference/pyspark.mllib.rst\n",
            "spark-3.1.2-bin-hadoop3.2/python/docs/source/reference/index.rst\n",
            "spark-3.1.2-bin-hadoop3.2/python/docs/source/reference/pyspark.sql.rst\n",
            "spark-3.1.2-bin-hadoop3.2/python/docs/source/reference/pyspark.ml.rst\n",
            "spark-3.1.2-bin-hadoop3.2/python/docs/source/migration_guide/\n",
            "spark-3.1.2-bin-hadoop3.2/python/docs/source/migration_guide/pyspark_2.3_to_2.4.rst\n",
            "spark-3.1.2-bin-hadoop3.2/python/docs/source/migration_guide/pyspark_2.3.0_to_2.3.1_above.rst\n",
            "spark-3.1.2-bin-hadoop3.2/python/docs/source/migration_guide/pyspark_2.2_to_2.3.rst\n",
            "spark-3.1.2-bin-hadoop3.2/python/docs/source/migration_guide/pyspark_1.4_to_1.5.rst\n",
            "spark-3.1.2-bin-hadoop3.2/python/docs/source/migration_guide/pyspark_1.0_1.2_to_1.3.rst\n",
            "spark-3.1.2-bin-hadoop3.2/python/docs/source/migration_guide/pyspark_2.4_to_3.0.rst\n",
            "spark-3.1.2-bin-hadoop3.2/python/docs/source/migration_guide/index.rst\n",
            "spark-3.1.2-bin-hadoop3.2/python/docs/source/getting_started/\n",
            "spark-3.1.2-bin-hadoop3.2/python/docs/source/getting_started/quickstart.ipynb\n",
            "spark-3.1.2-bin-hadoop3.2/python/docs/source/getting_started/index.rst\n",
            "spark-3.1.2-bin-hadoop3.2/python/docs/source/getting_started/install.rst\n",
            "spark-3.1.2-bin-hadoop3.2/python/docs/source/development/\n",
            "spark-3.1.2-bin-hadoop3.2/python/docs/source/development/testing.rst\n",
            "spark-3.1.2-bin-hadoop3.2/python/docs/source/development/setting_ide.rst\n",
            "spark-3.1.2-bin-hadoop3.2/python/docs/source/development/index.rst\n",
            "spark-3.1.2-bin-hadoop3.2/python/docs/source/development/debugging.rst\n",
            "spark-3.1.2-bin-hadoop3.2/python/docs/source/development/contributing.rst\n",
            "spark-3.1.2-bin-hadoop3.2/python/docs/source/_templates/\n",
            "spark-3.1.2-bin-hadoop3.2/python/docs/source/_templates/autosummary/\n",
            "spark-3.1.2-bin-hadoop3.2/python/docs/source/_templates/autosummary/class_with_docs.rst\n",
            "spark-3.1.2-bin-hadoop3.2/python/docs/source/_templates/autosummary/class.rst\n",
            "spark-3.1.2-bin-hadoop3.2/python/docs/source/_static/\n",
            "spark-3.1.2-bin-hadoop3.2/python/docs/source/_static/css/\n",
            "spark-3.1.2-bin-hadoop3.2/python/docs/source/_static/css/pyspark.css\n",
            "spark-3.1.2-bin-hadoop3.2/python/docs/source/_static/copybutton.js\n",
            "spark-3.1.2-bin-hadoop3.2/python/docs/source/index.rst\n",
            "spark-3.1.2-bin-hadoop3.2/python/docs/source/conf.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/docs/make.bat\n",
            "spark-3.1.2-bin-hadoop3.2/python/docs/make2.bat\n",
            "spark-3.1.2-bin-hadoop3.2/python/docs/Makefile\n",
            "spark-3.1.2-bin-hadoop3.2/python/README.md\n",
            "spark-3.1.2-bin-hadoop3.2/python/MANIFEST.in\n",
            "spark-3.1.2-bin-hadoop3.2/python/.gitignore\n",
            "spark-3.1.2-bin-hadoop3.2/python/.coveragerc\n",
            "spark-3.1.2-bin-hadoop3.2/python/setup.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/run-tests.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/run-tests-with-coverage\n",
            "spark-3.1.2-bin-hadoop3.2/python/mypy.ini\n",
            "spark-3.1.2-bin-hadoop3.2/python/test_support/\n",
            "spark-3.1.2-bin-hadoop3.2/python/test_support/userlibrary.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/test_support/userlib-0.1.zip\n",
            "spark-3.1.2-bin-hadoop3.2/python/test_support/sql/\n",
            "spark-3.1.2-bin-hadoop3.2/python/test_support/sql/text-test.txt\n",
            "spark-3.1.2-bin-hadoop3.2/python/test_support/sql/streaming/\n",
            "spark-3.1.2-bin-hadoop3.2/python/test_support/sql/streaming/text-test.txt\n",
            "spark-3.1.2-bin-hadoop3.2/python/test_support/sql/people_array_utf16le.json\n",
            "spark-3.1.2-bin-hadoop3.2/python/test_support/sql/people_array.json\n",
            "spark-3.1.2-bin-hadoop3.2/python/test_support/sql/people1.json\n",
            "spark-3.1.2-bin-hadoop3.2/python/test_support/sql/people.json\n",
            "spark-3.1.2-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/\n",
            "spark-3.1.2-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/\n",
            "spark-3.1.2-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=9/\n",
            "spark-3.1.2-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/\n",
            "spark-3.1.2-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/part-r-00007.gz.parquet\n",
            "spark-3.1.2-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/.part-r-00007.gz.parquet.crc\n",
            "spark-3.1.2-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=10/\n",
            "spark-3.1.2-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/\n",
            "spark-3.1.2-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/part-r-00005.gz.parquet\n",
            "spark-3.1.2-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/.part-r-00005.gz.parquet.crc\n",
            "spark-3.1.2-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/\n",
            "spark-3.1.2-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/part-r-00004.gz.parquet\n",
            "spark-3.1.2-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/part-r-00002.gz.parquet\n",
            "spark-3.1.2-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/.part-r-00004.gz.parquet.crc\n",
            "spark-3.1.2-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/.part-r-00002.gz.parquet.crc\n",
            "spark-3.1.2-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2014/\n",
            "spark-3.1.2-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2014/month=9/\n",
            "spark-3.1.2-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/\n",
            "spark-3.1.2-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/part-r-00008.gz.parquet\n",
            "spark-3.1.2-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/.part-r-00008.gz.parquet.crc\n",
            "spark-3.1.2-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/_metadata\n",
            "spark-3.1.2-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/_common_metadata\n",
            "spark-3.1.2-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/_SUCCESS\n",
            "spark-3.1.2-bin-hadoop3.2/python/test_support/sql/orc_partitioned/\n",
            "spark-3.1.2-bin-hadoop3.2/python/test_support/sql/orc_partitioned/b=1/\n",
            "spark-3.1.2-bin-hadoop3.2/python/test_support/sql/orc_partitioned/b=1/c=1/\n",
            "spark-3.1.2-bin-hadoop3.2/python/test_support/sql/orc_partitioned/b=1/c=1/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n",
            "spark-3.1.2-bin-hadoop3.2/python/test_support/sql/orc_partitioned/b=1/c=1/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n",
            "spark-3.1.2-bin-hadoop3.2/python/test_support/sql/orc_partitioned/b=0/\n",
            "spark-3.1.2-bin-hadoop3.2/python/test_support/sql/orc_partitioned/b=0/c=0/\n",
            "spark-3.1.2-bin-hadoop3.2/python/test_support/sql/orc_partitioned/b=0/c=0/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n",
            "spark-3.1.2-bin-hadoop3.2/python/test_support/sql/orc_partitioned/b=0/c=0/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n",
            "spark-3.1.2-bin-hadoop3.2/python/test_support/sql/orc_partitioned/_SUCCESS\n",
            "spark-3.1.2-bin-hadoop3.2/python/test_support/sql/ages_newlines.csv\n",
            "spark-3.1.2-bin-hadoop3.2/python/test_support/sql/ages.csv\n",
            "spark-3.1.2-bin-hadoop3.2/python/test_support/hello/\n",
            "spark-3.1.2-bin-hadoop3.2/python/test_support/hello/sub_hello/\n",
            "spark-3.1.2-bin-hadoop3.2/python/test_support/hello/sub_hello/sub_hello.txt\n",
            "spark-3.1.2-bin-hadoop3.2/python/test_support/hello/hello.txt\n",
            "spark-3.1.2-bin-hadoop3.2/python/test_support/SimpleHTTPServer.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/test_coverage/\n",
            "spark-3.1.2-bin-hadoop3.2/python/test_coverage/sitecustomize.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/test_coverage/coverage_daemon.py\n",
            "spark-3.1.2-bin-hadoop3.2/python/test_coverage/conf/\n",
            "spark-3.1.2-bin-hadoop3.2/python/test_coverage/conf/spark-defaults.conf\n",
            "spark-3.1.2-bin-hadoop3.2/python/setup.cfg\n",
            "spark-3.1.2-bin-hadoop3.2/python/run-tests\n",
            "spark-3.1.2-bin-hadoop3.2/bin/\n",
            "spark-3.1.2-bin-hadoop3.2/bin/sparkR2.cmd\n",
            "spark-3.1.2-bin-hadoop3.2/bin/sparkR.cmd\n",
            "spark-3.1.2-bin-hadoop3.2/bin/sparkR\n",
            "spark-3.1.2-bin-hadoop3.2/bin/spark-submit2.cmd\n",
            "spark-3.1.2-bin-hadoop3.2/bin/spark-submit.cmd\n",
            "spark-3.1.2-bin-hadoop3.2/bin/spark-submit\n",
            "spark-3.1.2-bin-hadoop3.2/bin/spark-sql2.cmd\n",
            "spark-3.1.2-bin-hadoop3.2/bin/spark-sql.cmd\n",
            "spark-3.1.2-bin-hadoop3.2/bin/spark-sql\n",
            "spark-3.1.2-bin-hadoop3.2/bin/spark-shell2.cmd\n",
            "spark-3.1.2-bin-hadoop3.2/bin/spark-shell.cmd\n",
            "spark-3.1.2-bin-hadoop3.2/bin/spark-shell\n",
            "spark-3.1.2-bin-hadoop3.2/bin/spark-class2.cmd\n",
            "spark-3.1.2-bin-hadoop3.2/bin/spark-class.cmd\n",
            "spark-3.1.2-bin-hadoop3.2/bin/spark-class\n",
            "spark-3.1.2-bin-hadoop3.2/bin/run-example.cmd\n",
            "spark-3.1.2-bin-hadoop3.2/bin/run-example\n",
            "spark-3.1.2-bin-hadoop3.2/bin/pyspark.cmd\n",
            "spark-3.1.2-bin-hadoop3.2/bin/load-spark-env.sh\n",
            "spark-3.1.2-bin-hadoop3.2/bin/load-spark-env.cmd\n",
            "spark-3.1.2-bin-hadoop3.2/bin/find-spark-home.cmd\n",
            "spark-3.1.2-bin-hadoop3.2/bin/find-spark-home\n",
            "spark-3.1.2-bin-hadoop3.2/bin/docker-image-tool.sh\n",
            "spark-3.1.2-bin-hadoop3.2/bin/beeline.cmd\n",
            "spark-3.1.2-bin-hadoop3.2/bin/beeline\n",
            "spark-3.1.2-bin-hadoop3.2/bin/pyspark2.cmd\n",
            "spark-3.1.2-bin-hadoop3.2/bin/pyspark\n",
            "spark-3.1.2-bin-hadoop3.2/README.md\n",
            "spark-3.1.2-bin-hadoop3.2/conf/\n",
            "spark-3.1.2-bin-hadoop3.2/conf/workers.template\n",
            "spark-3.1.2-bin-hadoop3.2/conf/spark-env.sh.template\n",
            "spark-3.1.2-bin-hadoop3.2/conf/spark-defaults.conf.template\n",
            "spark-3.1.2-bin-hadoop3.2/conf/metrics.properties.template\n",
            "spark-3.1.2-bin-hadoop3.2/conf/log4j.properties.template\n",
            "spark-3.1.2-bin-hadoop3.2/conf/fairscheduler.xml.template\n",
            "spark-3.1.2-bin-hadoop3.2/data/\n",
            "spark-3.1.2-bin-hadoop3.2/data/streaming/\n",
            "spark-3.1.2-bin-hadoop3.2/data/streaming/AFINN-111.txt\n",
            "spark-3.1.2-bin-hadoop3.2/data/mllib/\n",
            "spark-3.1.2-bin-hadoop3.2/data/mllib/streaming_kmeans_data_test.txt\n",
            "spark-3.1.2-bin-hadoop3.2/data/mllib/sample_svm_data.txt\n",
            "spark-3.1.2-bin-hadoop3.2/data/mllib/sample_multiclass_classification_data.txt\n",
            "spark-3.1.2-bin-hadoop3.2/data/mllib/sample_movielens_data.txt\n",
            "spark-3.1.2-bin-hadoop3.2/data/mllib/sample_linear_regression_data.txt\n",
            "spark-3.1.2-bin-hadoop3.2/data/mllib/sample_libsvm_data.txt\n",
            "spark-3.1.2-bin-hadoop3.2/data/mllib/sample_lda_libsvm_data.txt\n",
            "spark-3.1.2-bin-hadoop3.2/data/mllib/sample_lda_data.txt\n",
            "spark-3.1.2-bin-hadoop3.2/data/mllib/sample_kmeans_data.txt\n",
            "spark-3.1.2-bin-hadoop3.2/data/mllib/sample_isotonic_regression_libsvm_data.txt\n",
            "spark-3.1.2-bin-hadoop3.2/data/mllib/sample_fpgrowth.txt\n",
            "spark-3.1.2-bin-hadoop3.2/data/mllib/sample_binary_classification_data.txt\n",
            "spark-3.1.2-bin-hadoop3.2/data/mllib/ridge-data/\n",
            "spark-3.1.2-bin-hadoop3.2/data/mllib/ridge-data/lpsa.data\n",
            "spark-3.1.2-bin-hadoop3.2/data/mllib/pic_data.txt\n",
            "spark-3.1.2-bin-hadoop3.2/data/mllib/pagerank_data.txt\n",
            "spark-3.1.2-bin-hadoop3.2/data/mllib/kmeans_data.txt\n",
            "spark-3.1.2-bin-hadoop3.2/data/mllib/iris_libsvm.txt\n",
            "spark-3.1.2-bin-hadoop3.2/data/mllib/images/\n",
            "spark-3.1.2-bin-hadoop3.2/data/mllib/images/partitioned/\n",
            "spark-3.1.2-bin-hadoop3.2/data/mllib/images/partitioned/cls=multichannel/\n",
            "spark-3.1.2-bin-hadoop3.2/data/mllib/images/partitioned/cls=multichannel/date=2018-02/\n",
            "spark-3.1.2-bin-hadoop3.2/data/mllib/images/partitioned/cls=multichannel/date=2018-02/grayscale.jpg\n",
            "spark-3.1.2-bin-hadoop3.2/data/mllib/images/partitioned/cls=multichannel/date=2018-02/chr30.4.184.jpg\n",
            "spark-3.1.2-bin-hadoop3.2/data/mllib/images/partitioned/cls=multichannel/date=2018-01/\n",
            "spark-3.1.2-bin-hadoop3.2/data/mllib/images/partitioned/cls=multichannel/date=2018-01/BGRA_alpha_60.png\n",
            "spark-3.1.2-bin-hadoop3.2/data/mllib/images/partitioned/cls=multichannel/date=2018-01/BGRA.png\n",
            "spark-3.1.2-bin-hadoop3.2/data/mllib/images/partitioned/cls=kittens/\n",
            "spark-3.1.2-bin-hadoop3.2/data/mllib/images/partitioned/cls=kittens/date=2018-02/\n",
            "spark-3.1.2-bin-hadoop3.2/data/mllib/images/partitioned/cls=kittens/date=2018-02/DP802813.jpg\n",
            "spark-3.1.2-bin-hadoop3.2/data/mllib/images/partitioned/cls=kittens/date=2018-02/DP153539.jpg\n",
            "spark-3.1.2-bin-hadoop3.2/data/mllib/images/partitioned/cls=kittens/date=2018-02/54893.jpg\n",
            "spark-3.1.2-bin-hadoop3.2/data/mllib/images/partitioned/cls=kittens/date=2018-01/\n",
            "spark-3.1.2-bin-hadoop3.2/data/mllib/images/partitioned/cls=kittens/date=2018-01/not-image.txt\n",
            "spark-3.1.2-bin-hadoop3.2/data/mllib/images/partitioned/cls=kittens/date=2018-01/29.5.a_b_EGDP022204.jpg\n",
            "spark-3.1.2-bin-hadoop3.2/data/mllib/images/origin/\n",
            "spark-3.1.2-bin-hadoop3.2/data/mllib/images/origin/multi-channel/\n",
            "spark-3.1.2-bin-hadoop3.2/data/mllib/images/origin/multi-channel/grayscale.jpg\n",
            "spark-3.1.2-bin-hadoop3.2/data/mllib/images/origin/multi-channel/chr30.4.184.jpg\n",
            "spark-3.1.2-bin-hadoop3.2/data/mllib/images/origin/multi-channel/BGRA_alpha_60.png\n",
            "spark-3.1.2-bin-hadoop3.2/data/mllib/images/origin/multi-channel/BGRA.png\n",
            "spark-3.1.2-bin-hadoop3.2/data/mllib/images/origin/license.txt\n",
            "spark-3.1.2-bin-hadoop3.2/data/mllib/images/origin/kittens/\n",
            "spark-3.1.2-bin-hadoop3.2/data/mllib/images/origin/kittens/not-image.txt\n",
            "spark-3.1.2-bin-hadoop3.2/data/mllib/images/origin/kittens/DP802813.jpg\n",
            "spark-3.1.2-bin-hadoop3.2/data/mllib/images/origin/kittens/DP153539.jpg\n",
            "spark-3.1.2-bin-hadoop3.2/data/mllib/images/origin/kittens/54893.jpg\n",
            "spark-3.1.2-bin-hadoop3.2/data/mllib/images/origin/kittens/29.5.a_b_EGDP022204.jpg\n",
            "spark-3.1.2-bin-hadoop3.2/data/mllib/images/license.txt\n",
            "spark-3.1.2-bin-hadoop3.2/data/mllib/gmm_data.txt\n",
            "spark-3.1.2-bin-hadoop3.2/data/mllib/als/\n",
            "spark-3.1.2-bin-hadoop3.2/data/mllib/als/test.data\n",
            "spark-3.1.2-bin-hadoop3.2/data/mllib/als/sample_movielens_ratings.txt\n",
            "spark-3.1.2-bin-hadoop3.2/data/graphx/\n",
            "spark-3.1.2-bin-hadoop3.2/data/graphx/users.txt\n",
            "spark-3.1.2-bin-hadoop3.2/data/graphx/followers.txt\n",
            "spark-3.1.2-bin-hadoop3.2/NOTICE\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-zstd.txt\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-zstd-jni.txt\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-xmlenc.txt\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-vis-timeline.txt\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-spire.txt\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-sorttable.js.txt\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-slf4j.txt\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-scopt.txt\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-scala.txt\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-sbt-launch-lib.txt\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-respond.txt\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-reflectasm.txt\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-re2j.txt\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-pyrolite.txt\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-py4j.txt\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-protobuf.txt\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-pmml-model.txt\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-paranamer.txt\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-netlib.txt\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-mustache.txt\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-modernizr.txt\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-minlog.txt\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-matchMedia-polyfill.txt\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-machinist.txt\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-leveldbjni.txt\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-kryo.txt\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-jsp-api.txt\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-json-formatter.txt\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-jquery.txt\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-join.txt\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-jodd.txt\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-jline.txt\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-jaxb-runtime.txt\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-javolution.txt\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-javax-transaction-transaction-api.txt\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-javassist.html\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-janino.txt\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-jakarta.xml.bind-api.txt\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-jakarta.activation-api.txt\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-jakarta-ws-rs-api\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-jakarta-annotation-api\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-istack-commons-runtime.txt\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-graphlib-dot.txt\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-f2j.txt\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-dnsjava.txt\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-datatables.txt\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-dagre-d3.txt\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-d3.min.js.txt\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-cloudpickle.txt\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-bootstrap.txt\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-automaton.txt\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-arpack.txt\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-antlr.txt\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-JTransforms.txt\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-JLargeArrays.txt\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-CC0.txt\n",
            "spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-AnchorJS.txt\n",
            "spark-3.1.2-bin-hadoop3.2/LICENSE\n",
            "spark-3.1.2-bin-hadoop3.2/examples/\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/PrefixSpanExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/PowerIterationClusteringExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/PMMLModelExportExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnSourceVectorExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnRowMatrixExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/NormalizerExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/NaiveBayesExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/MultivariateSummarizer.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/MulticlassMetricsExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/MultiLabelMetricsExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/MovieLensALS.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/LogisticRegressionWithLBFGSExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/LatentDirichletAllocationExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/LDAExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/LBFGSExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/KernelDensityEstimationExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/KMeansExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/IsotonicRegressionExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingKolmogorovSmirnovTestExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingRegressionExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingClassificationExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostedTreesRunner.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/GaussianMixtureExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/FPGrowthExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/ElementwiseProductExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/DenseKMeans.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRunner.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRegressionExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeClassificationExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/CosineSimilarity.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/CorrelationsExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/Correlations.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/ChiSqSelectorExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/BisectingKMeansExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassificationMetricsExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassification.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/AssociationRulesExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/AbstractParams.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/Word2VecExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnySVD.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnyPCA.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/TFIDFExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/SummaryStatisticsExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingTestExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLogisticRegression.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLinearRegressionExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingKMeansExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/StratifiedSamplingExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/StandardScalerExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/SparseNaiveBayes.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/SimpleFPGrowth.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/SampledRDDs.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/SVMWithSGDExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/SVDExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/RecommendationExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/RankingMetricsExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/RandomRDDGeneration.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestRegressionExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestClassificationExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/Word2VecExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/VectorSlicerExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/VectorSizeHintExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/VectorIndexerExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/VectorAssemblerExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/VarianceThresholdSelectorExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/UnivariateFeatureSelectorExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/UnaryTransformerExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/TokenizerExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/TfIdfExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/SummarizerExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/StringIndexerExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/StopWordsRemoverExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/StandardScalerExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/SQLTransformerExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/RobustScalerExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestRegressorExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestClassifierExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/RFormulaExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/QuantileDiscretizerExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/PrefixSpanExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/PowerIterationClusteringExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/PolynomialExpansionExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/PipelineExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/PCAExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/OneVsRestExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/OneHotEncoderExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/NormalizerExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/NaiveBayesExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/NGramExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/MultilayerPerceptronClassifierExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/MulticlassLogisticRegressionWithElasticNetExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaTrainValidationSplitExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaCrossValidationExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/MinMaxScalerExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/MinHashLSHExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/MaxAbsScalerExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionWithElasticNetExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionSummaryExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/LinearSVCExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionWithElasticNetExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/LDAExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/KMeansExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/IsotonicRegressionExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/InteractionExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/IndexToStringExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/ImputerExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeRegressorExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeClassifierExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/GeneralizedLinearRegressionExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/GaussianMixtureExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/GBTExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/FeatureHasherExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/FPGrowthExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/FMRegressorExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/FMClassifierExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/EstimatorTransformerParamExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/ElementwiseProductExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/DeveloperApiExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeRegressionExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeClassificationExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/DataFrameExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/DCTExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/CountVectorizerExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/CorrelationExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/ChiSquareTestExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/ChiSqSelectorExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/BucketizerExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/BucketedRandomProjectionLSHExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/BisectingKMeansExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/BinarizerExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/ALSExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/AFTSurvivalRegressionExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/TriangleCountingExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/SynthBenchmark.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/SSSPExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/PageRankExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/LiveJournalPageRank.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/ConnectedComponentsExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/ComprehensiveExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/Analytics.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/AggregateMessagesExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SparkTC.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SparkRemoteFileTest.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SparkPi.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SparkPageRank.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SparkLR.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SparkKMeans.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SparkHdfsLR.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SparkALS.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SkewedGroupByTest.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SimpleSkewedGroupByTest.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/MultiBroadcastTest.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/LogQuery.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/LocalPi.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/LocalLR.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/LocalFileLR.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/LocalALS.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/HdfsTest.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/GroupByTest.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ExceptionHandlingTest.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/LocalKMeans.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/DriverSubmissionTest.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/DFSReadWriteTest.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/BroadcastTest.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/AccumulatorMetricsTest.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewStream.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewGenerator.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/StreamingExamples.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/StatefulNetworkWordCount.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/SqlNetworkWordCount.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/RecoverableNetworkWordCount.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/RawNetworkGrep.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/QueueStream.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/NetworkWordCount.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/HdfsWordCount.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKerberizedKafkaWordCount.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKafkaWordCount.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/CustomReceiver.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/streaming/\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredSessionization.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCountWindowed.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCount.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKerberizedKafkaWordCount.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKafkaWordCount.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/hive/\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/hive/SparkHiveExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedUntypedAggregation.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedTypedAggregation.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedScalar.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/SparkSQLExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/RDDRelation.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/SimpleTypedAggregator.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/SQLDataSourceExample.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/pythonconverters/\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/pythonconverters/AvroConverters.scala\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/resources/\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/resources/users.parquet\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/resources/users.orc\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/resources/users.avro\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/resources/user.avsc\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/resources/people.txt\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/resources/people.json\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/resources/people.csv\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/resources/kv1.txt\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/resources/full_user.avsc\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/resources/employees.json\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/resources/dir1/\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/resources/dir1/file3.json\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/resources/dir1/file1.parquet\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/resources/dir1/dir2/\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/resources/dir1/dir2/file2.parquet\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/r/\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/r/streaming/\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/r/streaming/structured_network_wordcount.R\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/r/ml/\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/r/ml/svmLinear.R\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/r/ml/survreg.R\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/r/ml/randomForest.R\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/r/ml/prefixSpan.R\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/r/ml/powerIterationClustering.R\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/r/ml/naiveBayes.R\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/r/ml/mlp.R\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/r/ml/ml.R\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/r/ml/logit.R\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/r/ml/lm_with_elastic_net.R\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/r/ml/lda.R\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/r/ml/kstest.R\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/r/ml/kmeans.R\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/r/ml/isoreg.R\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/r/ml/glm.R\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/r/ml/gbt.R\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/r/ml/gaussianMixture.R\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/r/ml/fpm.R\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/r/ml/fmRegressor.R\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/r/ml/fmClassifier.R\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/r/ml/decisionTree.R\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/r/ml/bisectingKmeans.R\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/r/ml/als.R\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/r/dataframe.R\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/r/data-manipulation.R\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/r/RSparkSQLExample.R\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/wordcount.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/transitive_closure.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/streaming/\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/streaming/stateful_network_wordcount.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/streaming/sql_network_wordcount.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/streaming/recoverable_network_wordcount.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/streaming/queue_stream.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/streaming/network_wordjoinsentiments.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/streaming/network_wordcount.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/streaming/hdfs_wordcount.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/status_api_demo.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/sql/\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/sql/streaming/\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/sql/streaming/structured_network_wordcount_windowed.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/sql/streaming/structured_network_wordcount.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/sql/streaming/structured_kafka_wordcount.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/sql/hive.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/sql/basic.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/sql/arrow.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/sql/datasource.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/sort.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/pi.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/parquet_inputformat.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/pagerank.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/word2vec_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/word2vec.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/tf_idf_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/svm_with_sgd_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/svd_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/summary_statistics_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/streaming_linear_regression_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/streaming_k_means_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/stratified_sampling_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/standard_scaler_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/sampled_rdds.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/regression_metrics_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/recommendation_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/ranking_metrics_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/random_rdd_generation.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/random_forest_regression_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/random_forest_classification_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/power_iteration_clustering_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/pca_rowmatrix_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/normalizer_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/naive_bayes_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/multi_label_metrics_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/multi_class_metrics_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/logistic_regression_with_lbfgs_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/logistic_regression.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/linear_regression_with_sgd_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/latent_dirichlet_allocation_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/kmeans.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/kernel_density_estimation_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/k_means_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/isotonic_regression_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/hypothesis_testing_kolmogorov_smirnov_test_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/hypothesis_testing_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/gradient_boosting_regression_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/gradient_boosting_classification_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/gaussian_mixture_model.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/gaussian_mixture_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/fpgrowth_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/elementwise_product_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/decision_tree_regression_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/decision_tree_classification_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/correlations_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/correlations.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/bisecting_k_means_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/binary_classification_metrics_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/word2vec_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/vector_slicer_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/vector_size_hint_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/vector_indexer_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/vector_assembler_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/variance_threshold_selector_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/univariate_feature_selector_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/train_validation_split.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/tokenizer_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/tf_idf_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/summarizer_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/string_indexer_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/stopwords_remover_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/standard_scaler_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/sql_transformer.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/robust_scaler_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/rformula_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/random_forest_regressor_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/random_forest_classifier_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/quantile_discretizer_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/prefixspan_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/power_iteration_clustering_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/polynomial_expansion_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/pipeline_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/pca_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/onehot_encoder_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/one_vs_rest_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/normalizer_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/naive_bayes_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/n_gram_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/multilayer_perceptron_classification.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/multiclass_logistic_regression_with_elastic_net.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/min_max_scaler_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/min_hash_lsh_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/max_abs_scaler_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/logistic_regression_with_elastic_net.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/logistic_regression_summary_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/linearsvc.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/linear_regression_with_elastic_net.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/lda_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/kmeans_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/isotonic_regression_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/interaction_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/index_to_string_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/imputer_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/gradient_boosted_tree_regressor_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/gradient_boosted_tree_classifier_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/generalized_linear_regression_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/gaussian_mixture_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/fpgrowth_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/fm_regressor_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/fm_classifier_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/feature_hasher_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/estimator_transformer_param_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/elementwise_product_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/decision_tree_regression_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/decision_tree_classification_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/dct_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/dataframe_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/cross_validator.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/count_vectorizer_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/correlation_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/chisq_selector_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/chi_square_test_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/bucketizer_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/bucketed_random_projection_lsh_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/bisecting_k_means_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/binarizer_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/als_example.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/aft_survival_regression.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/logistic_regression.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/kmeans.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/avro_inputformat.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/python/als.py\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scripts/\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/scripts/getGpusResources.sh\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaStatefulNetworkWordCount.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaSqlNetworkWordCount.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecoverableNetworkWordCount.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecord.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaQueueStream.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaNetworkWordCount.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKerberizedKafkaWordCount.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKafkaWordCount.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaCustomReceiver.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/streaming/\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredSessionization.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCountWindowed.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCount.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKerberizedKafkaWordCount.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKafkaWordCount.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/hive/\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/hive/JavaSparkHiveExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedUntypedAggregation.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedTypedAggregation.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedScalar.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/JavaSparkSQLExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/JavaSQLDataSourceExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaSummaryStatisticsExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaStreamingTestExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaStratifiedSamplingExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaSimpleFPGrowth.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVMWithSGDExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVDExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaRecommendationExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaRankingMetricsExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestRegressionExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestClassificationExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaPrefixSpanExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaPowerIterationClusteringExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaPCAExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaNaiveBayesExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaMulticlassClassificationMetricsExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaMultiLabelClassificationMetricsExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaLogisticRegressionWithLBFGSExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaLatentDirichletAllocationExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaLBFGSExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaKernelDensityEstimationExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaKMeansExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaIsotonicRegressionExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingKolmogorovSmirnovTestExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingRegressionExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingClassificationExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaGaussianMixtureExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaElementwiseProductExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeRegressionExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeClassificationExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaCorrelationsExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaChiSqSelectorExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaBisectingKMeansExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaBinaryClassificationMetricsExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaAssociationRulesExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaALS.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaWord2VecExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSlicerExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSizeHintExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorIndexerExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorAssemblerExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaVarianceThresholdSelectorExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaUnivariateFeatureSelectorExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaTfIdfExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaSummarizerExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaStringIndexerExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaStopWordsRemoverExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaStandardScalerExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaSQLTransformerExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaRobustScalerExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestRegressorExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestClassifierExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaRFormulaExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaQuantileDiscretizerExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaPrefixSpanExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaPowerIterationClusteringExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaPolynomialExpansionExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaPipelineExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaPCAExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaOneVsRestExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaOneHotEncoderExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaNormalizerExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaNaiveBayesExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaNGramExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaMultilayerPerceptronClassifierExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaMulticlassLogisticRegressionWithElasticNetExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaTrainValidationSplitExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaCrossValidationExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaMinMaxScalerExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaMinHashLSHExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaMaxAbsScalerExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionWithElasticNetExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionSummaryExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearSVCExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearRegressionWithElasticNetExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaLabeledDocument.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaLDAExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaKMeansExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaIsotonicRegressionExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaInteractionExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaIndexToStringExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaImputerExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeRegressorExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeClassifierExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaGeneralizedLinearRegressionExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaGaussianMixtureExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaFeatureHasherExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaFPGrowthExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaFMRegressorExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaFMClassifierExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaEstimatorTransformerParamExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaElementwiseProductExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaDocument.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeRegressionExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeClassificationExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaDCTExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaCountVectorizerExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaCorrelationExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSquareTestExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSqSelectorExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketizerExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketedRandomProjectionLSHExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaBisectingKMeansExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaBinarizerExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaALSExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaAFTSurvivalRegressionExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaTokenizerExample.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/JavaWordCount.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/JavaTC.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/JavaStatusTrackerDemo.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/JavaSparkPi.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/JavaPageRank.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/JavaLogQuery.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/JavaHdfsLR.java\n",
            "spark-3.1.2-bin-hadoop3.2/examples/jars/\n",
            "spark-3.1.2-bin-hadoop3.2/examples/jars/spark-examples_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop3.2/examples/jars/scopt_2.12-3.7.1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/kubernetes/\n",
            "spark-3.1.2-bin-hadoop3.2/kubernetes/tests/\n",
            "spark-3.1.2-bin-hadoop3.2/kubernetes/tests/worker_memory_check.py\n",
            "spark-3.1.2-bin-hadoop3.2/kubernetes/tests/python_executable_check.py\n",
            "spark-3.1.2-bin-hadoop3.2/kubernetes/tests/pyfiles.py\n",
            "spark-3.1.2-bin-hadoop3.2/kubernetes/tests/py_container_checks.py\n",
            "spark-3.1.2-bin-hadoop3.2/kubernetes/tests/decommissioning_cleanup.py\n",
            "spark-3.1.2-bin-hadoop3.2/kubernetes/tests/decommissioning.py\n",
            "spark-3.1.2-bin-hadoop3.2/kubernetes/tests/autoscale.py\n",
            "spark-3.1.2-bin-hadoop3.2/kubernetes/dockerfiles/\n",
            "spark-3.1.2-bin-hadoop3.2/kubernetes/dockerfiles/spark/\n",
            "spark-3.1.2-bin-hadoop3.2/kubernetes/dockerfiles/spark/bindings/\n",
            "spark-3.1.2-bin-hadoop3.2/kubernetes/dockerfiles/spark/bindings/python/\n",
            "spark-3.1.2-bin-hadoop3.2/kubernetes/dockerfiles/spark/bindings/python/Dockerfile\n",
            "spark-3.1.2-bin-hadoop3.2/kubernetes/dockerfiles/spark/bindings/R/\n",
            "spark-3.1.2-bin-hadoop3.2/kubernetes/dockerfiles/spark/bindings/R/Dockerfile\n",
            "spark-3.1.2-bin-hadoop3.2/kubernetes/dockerfiles/spark/Dockerfile\n",
            "spark-3.1.2-bin-hadoop3.2/kubernetes/dockerfiles/spark/entrypoint.sh\n",
            "spark-3.1.2-bin-hadoop3.2/kubernetes/dockerfiles/spark/decom.sh\n",
            "spark-3.1.2-bin-hadoop3.2/yarn/\n",
            "spark-3.1.2-bin-hadoop3.2/yarn/spark-3.1.2-yarn-shuffle.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/\n",
            "spark-3.1.2-bin-hadoop3.2/jars/zstd-jni-1.4.8-1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/zookeeper-3.4.14.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/zjsonpatch-0.3.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/xz-1.5.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/xbean-asm7-shaded-4.15.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/woodstox-core-5.0.3.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/velocity-1.5.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/univocity-parsers-2.9.1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/transaction-api-1.1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/token-provider-1.0.1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/threeten-extra-1.5.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/super-csv-2.2.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/stream-2.9.6.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/stax2-api-3.1.4.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/stax-api-1.0.1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/spire_2.12-0.17.0-M1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/spire-util_2.12-0.17.0-M1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/spire-platform_2.12-0.17.0-M1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/spire-macros_2.12-0.17.0-M1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/spark-yarn_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/spark-tags_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/spark-tags_2.12-3.1.2-tests.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/spark-streaming_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/spark-sql_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/spark-sketch_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/spark-repl_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/spark-network-shuffle_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/spark-network-common_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/spark-mllib_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/spark-mllib-local_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/spark-mesos_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/spark-launcher_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/spark-kvstore_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/spark-kubernetes_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/spark-hive_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/spark-hive-thriftserver_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/spark-graphx_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/spark-core_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/spark-catalyst_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/snappy-java-1.1.8.2.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/snakeyaml-1.24.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/slf4j-log4j12-1.7.30.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/slf4j-api-1.7.30.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/shims-0.9.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/shapeless_2.12-2.3.3.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/scala-xml_2.12-1.2.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/scala-reflect-2.12.10.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/scala-parser-combinators_2.12-1.1.2.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/scala-library-2.12.10.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/scala-compiler-2.12.10.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/scala-collection-compat_2.12-2.1.1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/re2j-1.1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/pyrolite-4.30.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/py4j-0.10.9.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/protobuf-java-2.5.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/parquet-jackson-1.10.1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/parquet-hadoop-1.10.1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/parquet-format-2.4.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/parquet-encoding-1.10.1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/parquet-common-1.10.1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/parquet-column-1.10.1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/paranamer-2.8.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/osgi-resource-locator-1.0.3.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/oro-2.0.8.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/orc-shims-1.5.12.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/orc-mapreduce-1.5.12.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/orc-core-1.5.12.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/opencsv-2.3.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/okio-1.14.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/okhttp-3.12.12.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/okhttp-2.7.5.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/objenesis-2.6.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/nimbus-jose-jwt-4.41.1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/netty-all-4.1.51.Final.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/minlog-1.3.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/metrics-jvm-4.1.1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/metrics-json-4.1.1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/metrics-jmx-4.1.1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/metrics-graphite-4.1.1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/metrics-core-4.1.1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/mesos-1.4.0-shaded-protobuf.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/macro-compat_2.12-1.1.1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/machinist_2.12-0.6.8.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/lz4-java-1.7.1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/logging-interceptor-3.12.12.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/log4j-1.2.17.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/libthrift-0.12.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/libfb303-0.9.3.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/leveldbjni-all-1.8.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/kubernetes-model-storageclass-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/kubernetes-model-settings-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/kubernetes-model-scheduling-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/kubernetes-model-rbac-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/kubernetes-model-policy-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/kubernetes-model-networking-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/kubernetes-model-metrics-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/kubernetes-model-extensions-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/kubernetes-model-events-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/kubernetes-model-discovery-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/kubernetes-model-core-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/kubernetes-model-coordination-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/kubernetes-model-common-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/kubernetes-model-certificates-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/kubernetes-model-batch-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/kubernetes-model-autoscaling-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/kubernetes-model-apps-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/kubernetes-model-apiextensions-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/kubernetes-model-admissionregistration-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/kubernetes-client-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/kryo-shaded-4.0.2.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/kerby-xdr-1.0.1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/kerby-util-1.0.1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/kerby-pkix-1.0.1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/kerby-config-1.0.1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/kerby-asn1-1.0.1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/kerb-util-1.0.1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/kerb-simplekdc-1.0.1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/kerb-server-1.0.1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/kerb-identity-1.0.1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/kerb-crypto-1.0.1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/kerb-core-1.0.1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/kerb-common-1.0.1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/kerb-client-1.0.1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/kerb-admin-1.0.1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/jul-to-slf4j-1.7.30.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/jta-1.1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/jsr305-3.0.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/jsp-api-2.1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/json4s-scalap_2.12-3.7.0-M5.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/json4s-jackson_2.12-3.7.0-M5.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/json4s-core_2.12-3.7.0-M5.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/json4s-ast_2.12-3.7.0-M5.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/json-smart-2.3.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/json-1.8.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/jpam-1.1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/jodd-core-3.5.2.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/joda-time-2.10.5.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/jline-2.14.6.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/jersey-server-2.30.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/jersey-media-jaxb-2.30.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/jersey-hk2-2.30.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/jersey-container-servlet-core-2.30.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/jersey-container-servlet-2.30.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/jersey-common-2.30.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/jersey-client-2.30.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/jdo-api-3.0.1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/jcl-over-slf4j-1.7.30.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/jcip-annotations-1.0-1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/jaxb-runtime-2.3.2.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/jaxb-api-2.2.11.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/javolution-5.5.1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/javax.jdo-3.2.0-m3.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/javax.inject-1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/javassist-3.25.0-GA.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/janino-3.0.16.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/jakarta.xml.bind-api-2.3.2.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/jakarta.ws.rs-api-2.1.6.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/jakarta.validation-api-2.0.2.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/jakarta.servlet-api-4.0.3.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/jakarta.inject-2.6.1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/jakarta.annotation-api-1.3.5.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/jakarta.activation-api-1.2.1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/jackson-module-scala_2.12-2.10.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/jackson-module-paranamer-2.10.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/jackson-module-jaxb-annotations-2.10.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/jackson-mapper-asl-1.9.13.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/jackson-jaxrs-json-provider-2.9.5.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/jackson-jaxrs-base-2.9.5.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/jackson-datatype-jsr310-2.11.2.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/jackson-dataformat-yaml-2.10.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/jackson-databind-2.10.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/jackson-core-asl-1.9.13.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/jackson-core-2.10.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/jackson-annotations-2.10.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/ivy-2.4.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/istack-commons-runtime-3.0.8.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/httpcore-4.4.12.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/httpclient-4.5.6.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/htrace-core4-4.1.0-incubating.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/hk2-utils-2.6.1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/hk2-locator-2.6.1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/hk2-api-2.6.1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/hive-vector-code-gen-2.3.7.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/hive-storage-api-2.7.2.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/hive-shims-scheduler-2.3.7.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/hive-shims-common-2.3.7.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/hive-shims-2.3.7.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/hive-shims-0.23-2.3.7.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/hive-service-rpc-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/hive-serde-2.3.7.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/hive-metastore-2.3.7.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/hive-llap-common-2.3.7.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/hive-jdbc-2.3.7.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/hive-exec-2.3.7-core.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/hive-common-2.3.7.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/hive-cli-2.3.7.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/hive-beeline-2.3.7.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/hadoop-yarn-server-web-proxy-3.2.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/hadoop-yarn-server-common-3.2.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/hadoop-yarn-registry-3.2.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/hadoop-yarn-common-3.2.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/hadoop-yarn-client-3.2.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/hadoop-yarn-api-3.2.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/hadoop-mapreduce-client-jobclient-3.2.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/hadoop-mapreduce-client-core-3.2.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/hadoop-mapreduce-client-common-3.2.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/hadoop-hdfs-client-3.2.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/hadoop-common-3.2.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/hadoop-client-3.2.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/hadoop-auth-3.2.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/hadoop-annotations-3.2.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/guice-servlet-4.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/guice-4.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/guava-14.0.1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/gson-2.2.4.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/geronimo-jcache_1.0_spec-1.0-alpha-1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/generex-1.0.2.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/flatbuffers-java-1.9.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/ehcache-3.3.1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/dnsjava-2.1.7.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/derby-10.12.1.1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/datanucleus-rdbms-4.1.19.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/datanucleus-core-4.1.17.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/datanucleus-api-jdo-4.2.4.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/curator-recipes-2.13.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/curator-framework-2.13.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/curator-client-2.13.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/core-1.1.2.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/compress-lzf-1.0.3.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/commons-text-1.6.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/commons-pool-1.5.4.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/commons-net-3.1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/commons-math3-3.4.1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/commons-logging-1.1.3.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/commons-lang3-3.10.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/commons-lang-2.6.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/commons-io-2.5.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/commons-httpclient-3.1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/commons-dbcp-1.4.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/commons-daemon-1.0.13.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/commons-crypto-1.1.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/commons-configuration2-2.1.1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/commons-compress-1.20.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/commons-compiler-3.0.16.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/commons-collections-3.2.2.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/commons-codec-1.10.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/commons-cli-1.2.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/commons-beanutils-1.9.4.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/chill_2.12-0.9.5.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/chill-java-0.9.5.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/cats-kernel_2.12-2.0.0-M4.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/breeze_2.12-1.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/breeze-macros_2.12-1.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/bonecp-0.8.0.RELEASE.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/avro-mapred-1.8.2-hadoop2.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/avro-ipc-1.8.2.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/avro-1.8.2.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/automaton-1.11-8.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/audience-annotations-0.5.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/arrow-vector-2.0.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/arrow-memory-netty-2.0.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/arrow-memory-core-2.0.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/arrow-format-2.0.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/arpack_combined_all-0.1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/aopalliance-repackaged-2.6.1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/aopalliance-1.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/antlr4-runtime-4.8-1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/antlr-runtime-3.5.2.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/algebra_2.12-2.0.0-M2.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/aircompressor-0.10.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/activation-1.1.1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/accessors-smart-1.2.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/ST4-4.0.4.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/RoaringBitmap-0.9.0.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/JTransforms-3.1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/JLargeArrays-1.5.jar\n",
            "spark-3.1.2-bin-hadoop3.2/jars/HikariCP-2.5.1.jar\n",
            "spark-3.1.2-bin-hadoop3.2/RELEASE\n",
            "Requirement already satisfied: findspark in /usr/local/lib/python3.7/dist-packages (1.4.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oReSJ-K1Q-hT",
        "outputId": "c991288f-026f-4527-c028-b0c6145faf85"
      },
      "source": [
        "!ls\n",
        "\n",
        "!pyspark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data  spark-3.1.2-bin-hadoop3.2\tspark-3.1.2-bin-hadoop3.2.tgz\n",
            "/bin/bash: pyspark: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fi8lGjGdRk9y"
      },
      "source": [
        "import os\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop3.2\"\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26EZvT9YRv5Q",
        "outputId": "5bd22e2b-2491-4f9d-93da-8f485d328f91"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark import SparkConf\n",
        "from pyspark import SparkContext\n",
        "\n",
        "sc = SparkContext.getOrCreate(SparkConf().setMaster(\"local[*]\"))\n",
        "spark = SparkSession.builder.appName(\"PySpark 3.0 Setup on Google Colab\").getOrCreate()\n",
        "print(spark.sparkContext.appName)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PySpark 3.0 Setup on Google Colab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fe2Ce3AR1Lh",
        "outputId": "8c87a995-1f80-4221-dd10-d6d9a6f3f3e8"
      },
      "source": [
        "df = spark.read.csv(header=True, inferSchema=True, path=\"/content/NSE_RELIANCE_5_1.csv\")\n",
        "\n",
        "df.show(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+-----------+-----------+-----------+-----------+-----------+-----------+---+---+---+----+------+---------+------------+------------+------------+\n",
            "|               time|       open|       high|        low|      close|        MA5|        MA6|MA7|MA8|MA9|MA10|Volume|Volume MA|   Histogram|        MACD|      Signal|\n",
            "+-------------------+-----------+-----------+-----------+-----------+-----------+-----------+---+---+---+----+------+---------+------------+------------+------------+\n",
            "|2020-04-03 07:20:00|1053.771557|1056.297519|1051.790411|1053.424857|1056.784037|1055.267738|NaN|NaN|NaN| NaN|354666| 140161.0|-0.038974088|-1.535973794|-1.496999706|\n",
            "|2020-04-03 07:25:00|1053.573443|1055.455532|  1053.3258|1054.266844|1056.555201|1055.017514|NaN|NaN|NaN| NaN| 59611|133630.15|-0.051333212| -1.56116622|-1.509833009|\n",
            "+-------------------+-----------+-----------+-----------+-----------+-----------+-----------+---+---+---+----+------+---------+------------+------------+------------+\n",
            "only showing top 2 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPCKvZFVTW9N",
        "outputId": "06887882-5581-46a0-f6b5-31475cf537a5"
      },
      "source": [
        "df.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- time: timestamp (nullable = true)\n",
            " |-- open: double (nullable = true)\n",
            " |-- high: double (nullable = true)\n",
            " |-- low: double (nullable = true)\n",
            " |-- close: double (nullable = true)\n",
            " |-- MA5: double (nullable = true)\n",
            " |-- MA6: double (nullable = true)\n",
            " |-- MA7: double (nullable = true)\n",
            " |-- MA8: double (nullable = true)\n",
            " |-- MA9: double (nullable = true)\n",
            " |-- MA10: double (nullable = true)\n",
            " |-- Volume: integer (nullable = true)\n",
            " |-- Volume MA: double (nullable = true)\n",
            " |-- Histogram: double (nullable = true)\n",
            " |-- MACD: double (nullable = true)\n",
            " |-- Signal: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEtdlLzPTcXb"
      },
      "source": [
        "df.createOrReplaceTempView(\"trade\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WL3GGuXZTkVq",
        "outputId": "735b4e12-ceb5-4fde-950f-17d4920221e1"
      },
      "source": [
        "spark.sql(\"select * from trade limit 2\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+-----------+-----------+-----------+-----------+-----------+-----------+---+---+---+----+------+---------+------------+------------+------------+\n",
            "|               time|       open|       high|        low|      close|        MA5|        MA6|MA7|MA8|MA9|MA10|Volume|Volume MA|   Histogram|        MACD|      Signal|\n",
            "+-------------------+-----------+-----------+-----------+-----------+-----------+-----------+---+---+---+----+------+---------+------------+------------+------------+\n",
            "|2020-04-03 07:20:00|1053.771557|1056.297519|1051.790411|1053.424857|1056.784037|1055.267738|NaN|NaN|NaN| NaN|354666| 140161.0|-0.038974088|-1.535973794|-1.496999706|\n",
            "|2020-04-03 07:25:00|1053.573443|1055.455532|  1053.3258|1054.266844|1056.555201|1055.017514|NaN|NaN|NaN| NaN| 59611|133630.15|-0.051333212| -1.56116622|-1.509833009|\n",
            "+-------------------+-----------+-----------+-----------+-----------+-----------+-----------+---+---+---+----+------+---------+------------+------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpxDaOsnTrba"
      },
      "source": [
        "words=sc.textFile(\"/content/Shakespeare.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNZBMtGMV7v2",
        "outputId": "1ab92eae-c7f8-4cf7-f914-1481a904c7f8"
      },
      "source": [
        "words.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Project Gutenberg's Etext of Shakespeare's First Folio/35 Plays\",\n",
              " 'This is our 3rd edition of most of these plays.  See the index.',\n",
              " '',\n",
              " '',\n",
              " 'Copyright laws are changing all over the world, be sure to check',\n",
              " 'the copyright laws for your country before posting these files!!',\n",
              " '',\n",
              " 'Please take a look at the important information in this header.',\n",
              " 'We encourage you to keep this file on your own disk, keeping an',\n",
              " 'electronic path open for the next readers.  Do not remove this.',\n",
              " '',\n",
              " '',\n",
              " '**Welcome To The World of Free Plain Vanilla Electronic Texts**',\n",
              " '',\n",
              " '**Etexts Readable By Both Humans and By Computers, Since 1971**',\n",
              " '',\n",
              " '*These Etexts Prepared By Hundreds of Volunteers and Donations*',\n",
              " '',\n",
              " 'Information on contacting Project Gutenberg to get Etexts, and',\n",
              " 'further information is included below.  We need your donations.',\n",
              " '',\n",
              " '',\n",
              " 'The First Folio [35 Plays]',\n",
              " '',\n",
              " 'by William Shakespeare',\n",
              " '',\n",
              " 'July, 2000  [Etext #2270]',\n",
              " '',\n",
              " '',\n",
              " \"Project Gutenberg's Etext of Shakespeare's First Folio/35 Plays\",\n",
              " '*****This file should be named 00ws110.txt or 00ws110.zip******',\n",
              " '',\n",
              " 'Corrected EDITIONS of our etexts get a new NUMBER, 00ws111.txt',\n",
              " 'VERSIONS based on separate sources get new LETTER, 00ws110a.txt',\n",
              " '',\n",
              " '',\n",
              " 'Project Gutenberg Etexts are usually created from multiple editions,',\n",
              " 'all of which are in the Public Domain in the United States, unless a',\n",
              " 'copyright notice is included.  Therefore, we usually do NOT keep any',\n",
              " 'of these books in compliance with any particular paper edition.',\n",
              " '',\n",
              " '',\n",
              " 'We are now trying to release all our books one month in advance',\n",
              " 'of the official release dates, leaving time for better editing.',\n",
              " '',\n",
              " 'Please note:  neither this list nor its contents are final till',\n",
              " 'midnight of the last day of the month of any such announcement.',\n",
              " 'The official release date of all Project Gutenberg Etexts is at',\n",
              " 'Midnight, Central Time, of the last day of the stated month.  A',\n",
              " 'preliminary version may often be posted for suggestion, comment',\n",
              " 'and editing by those who wish to do so.  To be sure you have an',\n",
              " 'up to date first edition [xxxxx10x.xxx] please check file sizes',\n",
              " 'in the first week of the next month.  Since our ftp program has',\n",
              " 'a bug in it that scrambles the date [tried to fix and failed] a',\n",
              " 'look at the file size will have to do, but we will try to see a',\n",
              " 'new copy has at least one byte more or less.',\n",
              " '',\n",
              " '',\n",
              " 'Information about Project Gutenberg (one page)',\n",
              " '',\n",
              " 'We produce about two million dollars for each hour we work.  The',\n",
              " 'time it takes us, a rather conservative estimate, is fifty hours',\n",
              " 'to get any etext selected, entered, proofread, edited, copyright',\n",
              " 'searched and analyzed, the copyright letters written, etc.  This',\n",
              " 'projected audience is one hundred million readers.  If our value',\n",
              " 'per text is nominally estimated at one dollar then we produce $2',\n",
              " 'million dollars per hour this year as we release thirty-six text',\n",
              " 'files per month, or 432 more Etexts in 1999 for a total of 2000+',\n",
              " 'If these reach just 10% of the computerized population, then the',\n",
              " 'total should reach over 200 billion Etexts given away this year.',\n",
              " '',\n",
              " 'The Goal of Project Gutenberg is to Give Away One Trillion Etext',\n",
              " 'Files by December 31, 2001.  [10,000 x 100,000,000 = 1 Trillion]',\n",
              " 'This is ten thousand titles each to one hundred million readers,',\n",
              " 'which is only ~5% of the present number of computer users.',\n",
              " '',\n",
              " 'At our revised rates of production, we will reach only one-third',\n",
              " 'of that goal by the end of 2001, or about 3,333 Etexts unless we',\n",
              " 'manage to get some real funding; currently our funding is mostly',\n",
              " \"from Michael Hart's salary at Carnegie-Mellon University, and an\",\n",
              " 'assortment of sporadic gifts; this salary is only good for a few',\n",
              " 'more years, so we are looking for something to replace it, as we',\n",
              " \"don't want Project Gutenberg to be so dependent on one person.\",\n",
              " '',\n",
              " 'We need your donations more than ever!',\n",
              " '',\n",
              " '',\n",
              " 'All donations should be made to \"Project Gutenberg/CMU\": and are',\n",
              " 'tax deductible to the extent allowable by law.  (CMU = Carnegie-',\n",
              " 'Mellon University).',\n",
              " '',\n",
              " 'For these and other matters, please mail to:',\n",
              " '',\n",
              " 'Project Gutenberg',\n",
              " 'P. O. Box  2782',\n",
              " 'Champaign, IL 61825',\n",
              " '',\n",
              " 'When all other email fails. . .try our Executive Director:',\n",
              " 'Michael S. Hart <hart@pobox.com>',\n",
              " 'hart@pobox.com forwards to hart@prairienet.org and archive.org',\n",
              " 'if your mail bounces from archive.org, I will still see it, if',\n",
              " 'it bounces from prairienet.org, better resend later on. . . .',\n",
              " '',\n",
              " 'We would prefer to send you this information by email.',\n",
              " '',\n",
              " '******',\n",
              " '',\n",
              " 'To access Project Gutenberg etexts, use any Web browser',\n",
              " 'to view http://promo.net/pg.  This site lists Etexts by',\n",
              " 'author and by title, and includes information about how',\n",
              " 'to get involved with Project Gutenberg.  You could also',\n",
              " 'download our past Newsletters, or subscribe here.  This',\n",
              " 'is one of our major sites, please email hart@pobox.com,',\n",
              " 'for a more complete list of our various sites.',\n",
              " '',\n",
              " 'To go directly to the etext collections, use FTP or any',\n",
              " 'Web browser to visit a Project Gutenberg mirror (mirror',\n",
              " 'sites are available on 7 continents; mirrors are listed',\n",
              " 'at http://promo.net/pg).',\n",
              " '',\n",
              " 'Mac users, do NOT point and click, typing works better.',\n",
              " '',\n",
              " 'Example FTP session:',\n",
              " '',\n",
              " 'ftp sunsite.unc.edu',\n",
              " 'login: anonymous',\n",
              " 'password: your@login',\n",
              " 'cd pub/docs/books/gutenberg',\n",
              " 'cd etext90 through etext99',\n",
              " 'dir [to see files]',\n",
              " 'get or mget [to get files. . .set bin for zip files]',\n",
              " \"GET GUTINDEX.??  [to get a year's listing of books, e.g., GUTINDEX.99]\",\n",
              " 'GET GUTINDEX.ALL [to get a listing of ALL books]',\n",
              " '',\n",
              " '***',\n",
              " '',\n",
              " '**Information prepared by the Project Gutenberg legal advisor**',\n",
              " '',\n",
              " '(Three Pages)',\n",
              " '',\n",
              " '',\n",
              " '***START**THE SMALL PRINT!**FOR PUBLIC DOMAIN ETEXTS**START***',\n",
              " 'Why is this \"Small Print!\" statement here?  You know: lawyers.',\n",
              " 'They tell us you might sue us if there is something wrong with',\n",
              " 'your copy of this etext, even if you got it for free from',\n",
              " \"someone other than us, and even if what's wrong is not our\",\n",
              " 'fault.  So, among other things, this \"Small Print!\" statement',\n",
              " 'disclaims most of our liability to you.  It also tells you how',\n",
              " 'you can distribute copies of this etext if you want to.',\n",
              " '',\n",
              " '*BEFORE!* YOU USE OR READ THIS ETEXT',\n",
              " 'By using or reading any part of this PROJECT GUTENBERG-tm',\n",
              " 'etext, you indicate that you understand, agree to and accept',\n",
              " 'this \"Small Print!\" statement.  If you do not, you can receive',\n",
              " 'a refund of the money (if any) you paid for this etext by',\n",
              " 'sending a request within 30 days of receiving it to the person',\n",
              " 'you got it from.  If you received this etext on a physical',\n",
              " 'medium (such as a disk), you must return it with your request.',\n",
              " '',\n",
              " 'ABOUT PROJECT GUTENBERG-TM ETEXTS',\n",
              " 'This PROJECT GUTENBERG-tm etext, like most PROJECT GUTENBERG-',\n",
              " 'tm etexts, is a \"public domain\" work distributed by Professor',\n",
              " 'Michael S. Hart through the Project Gutenberg Association at',\n",
              " 'Carnegie-Mellon University (the \"Project\").  Among other',\n",
              " 'things, this means that no one owns a United States copyright',\n",
              " 'on or for this work, so the Project (and you!) can copy and',\n",
              " 'distribute it in the United States without permission and',\n",
              " 'without paying copyright royalties.  Special rules, set forth',\n",
              " 'below, apply if you wish to copy and distribute this etext',\n",
              " 'under the Project\\'s \"PROJECT GUTENBERG\" trademark.',\n",
              " '',\n",
              " 'To create these etexts, the Project expends considerable',\n",
              " 'efforts to identify, transcribe and proofread public domain',\n",
              " \"works.  Despite these efforts, the Project's etexts and any\",\n",
              " 'medium they may be on may contain \"Defects\".  Among other',\n",
              " 'things, Defects may take the form of incomplete, inaccurate or',\n",
              " 'corrupt data, transcription errors, a copyright or other',\n",
              " 'intellectual property infringement, a defective or damaged',\n",
              " 'disk or other etext medium, a computer virus, or computer',\n",
              " 'codes that damage or cannot be read by your equipment.',\n",
              " '',\n",
              " 'LIMITED WARRANTY; DISCLAIMER OF DAMAGES',\n",
              " 'But for the \"Right of Replacement or Refund\" described below,',\n",
              " '[1] the Project (and any other party you may receive this',\n",
              " 'etext from as a PROJECT GUTENBERG-tm etext) disclaims all',\n",
              " 'liability to you for damages, costs and expenses, including',\n",
              " 'legal fees, and [2] YOU HAVE NO REMEDIES FOR NEGLIGENCE OR',\n",
              " 'UNDER STRICT LIABILITY, OR FOR BREACH OF WARRANTY OR CONTRACT,',\n",
              " 'INCLUDING BUT NOT LIMITED TO INDIRECT, CONSEQUENTIAL, PUNITIVE',\n",
              " 'OR INCIDENTAL DAMAGES, EVEN IF YOU GIVE NOTICE OF THE',\n",
              " 'POSSIBILITY OF SUCH DAMAGES.',\n",
              " '',\n",
              " 'If you discover a Defect in this etext within 90 days of',\n",
              " 'receiving it, you can receive a refund of the money (if any)',\n",
              " 'you paid for it by sending an explanatory note within that',\n",
              " 'time to the person you received it from.  If you received it',\n",
              " 'on a physical medium, you must return it with your note, and',\n",
              " 'such person may choose to alternatively give you a replacement',\n",
              " 'copy.  If you received it electronically, such person may',\n",
              " 'choose to alternatively give you a second opportunity to',\n",
              " 'receive it electronically.',\n",
              " '',\n",
              " 'THIS ETEXT IS OTHERWISE PROVIDED TO YOU \"AS-IS\".  NO OTHER',\n",
              " 'WARRANTIES OF ANY KIND, EXPRESS OR IMPLIED, ARE MADE TO YOU AS',\n",
              " 'TO THE ETEXT OR ANY MEDIUM IT MAY BE ON, INCLUDING BUT NOT',\n",
              " 'LIMITED TO WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A',\n",
              " 'PARTICULAR PURPOSE.',\n",
              " '',\n",
              " 'Some states do not allow disclaimers of implied warranties or',\n",
              " 'the exclusion or limitation of consequential damages, so the',\n",
              " 'above disclaimers and exclusions may not apply to you, and you',\n",
              " 'may have other legal rights.',\n",
              " '',\n",
              " 'INDEMNITY',\n",
              " 'You will indemnify and hold the Project, its directors,',\n",
              " 'officers, members and agents harmless from all liability, cost',\n",
              " 'and expense, including legal fees, that arise directly or',\n",
              " 'indirectly from any of the following that you do or cause:',\n",
              " '[1] distribution of this etext, [2] alteration, modification,',\n",
              " 'or addition to the etext, or [3] any Defect.',\n",
              " '',\n",
              " 'DISTRIBUTION UNDER \"PROJECT GUTENBERG-tm\"',\n",
              " 'You may distribute copies of this etext electronically, or by',\n",
              " 'disk, book or any other medium if you either delete this',\n",
              " '\"Small Print!\" and all other references to Project Gutenberg,',\n",
              " 'or:',\n",
              " '',\n",
              " '[1]  Only give exact copies of it.  Among other things, this',\n",
              " '     requires that you do not remove, alter or modify the',\n",
              " '     etext or this \"small print!\" statement.  You may however,',\n",
              " '     if you wish, distribute this etext in machine readable',\n",
              " '     binary, compressed, mark-up, or proprietary form,',\n",
              " '     including any form resulting from conversion by word pro-',\n",
              " '     cessing or hypertext software, but only so long as',\n",
              " '     *EITHER*:',\n",
              " '',\n",
              " '     [*]  The etext, when displayed, is clearly readable, and',\n",
              " '          does *not* contain characters other than those',\n",
              " '          intended by the author of the work, although tilde',\n",
              " '          (~), asterisk (*) and underline (_) characters may',\n",
              " '          be used to convey punctuation intended by the',\n",
              " '          author, and additional characters may be used to',\n",
              " '          indicate hypertext links; OR',\n",
              " '',\n",
              " '     [*]  The etext may be readily converted by the reader at',\n",
              " '          no expense into plain ASCII, EBCDIC or equivalent',\n",
              " '          form by the program that displays the etext (as is',\n",
              " '          the case, for instance, with most word processors);',\n",
              " '          OR',\n",
              " '',\n",
              " '     [*]  You provide, or agree to also provide on request at',\n",
              " '          no additional cost, fee or expense, a copy of the',\n",
              " '          etext in its original plain ASCII form (or in EBCDIC',\n",
              " '          or other equivalent proprietary form).',\n",
              " '',\n",
              " '[2]  Honor the etext refund and replacement provisions of this',\n",
              " '     \"Small Print!\" statement.',\n",
              " '',\n",
              " '[3]  Pay a trademark license fee to the Project of 20% of the',\n",
              " '     net profits you derive calculated using the method you',\n",
              " '     already use to calculate your applicable taxes.  If you',\n",
              " \"     don't derive profits, no royalty is due.  Royalties are\",\n",
              " '     payable to \"Project Gutenberg Association/Carnegie-Mellon',\n",
              " '     University\" within the 60 days following each',\n",
              " '     date you prepare (or were legally required to prepare)',\n",
              " '     your annual (or equivalent periodic) tax return.',\n",
              " '',\n",
              " \"WHAT IF YOU *WANT* TO SEND MONEY EVEN IF YOU DON'T HAVE TO?\",\n",
              " 'The Project gratefully accepts contributions in money, time,',\n",
              " 'scanning machines, OCR software, public domain etexts, royalty',\n",
              " 'free copyright licenses, and every other sort of contribution',\n",
              " 'you can think of.  Money should be paid to \"Project Gutenberg',\n",
              " 'Association / Carnegie-Mellon University\".',\n",
              " '',\n",
              " '*END*THE SMALL PRINT! FOR PUBLIC DOMAIN ETEXTS*Ver.04.29.93*END*',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " \"Project Gutenberg's Etext of Shakespeare's First Folio/35 Plays\",\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " \"Executive Director's Notes:\",\n",
              " '',\n",
              " 'In addition to the notes below, and so you will *NOT* think all',\n",
              " 'the spelling errors introduced by the printers of the time have',\n",
              " 'been corrected, here are the first few lines of Hamlet, as they',\n",
              " 'are presented herein:',\n",
              " '',\n",
              " \"  Barnardo. Who's there?\",\n",
              " '  Fran. Nay answer me: Stand & vnfold',\n",
              " 'your selfe',\n",
              " '',\n",
              " '   Bar. Long liue the King',\n",
              " '',\n",
              " '***',\n",
              " '',\n",
              " 'As I understand it, the printers often ran out of certain words',\n",
              " 'or letters they had often packed into a \"cliche\". . .this is the',\n",
              " 'original meaning of the term cliche. . .and thus, being unwilling',\n",
              " 'to unpack the cliches, and thus you will see some substitutions',\n",
              " 'that look very odd. . .such as the exchanges of u for v, v for u,',\n",
              " 'above. . .and you may wonder why they did it this way, presuming',\n",
              " 'Shakespeare did not actually write the play in this manner. . . .',\n",
              " '',\n",
              " 'The answer is that they MAY have packed \"liue\" into a cliche at a',\n",
              " 'time when they were out of \"v\"\\'s. . .possibly having used \"vv\" in',\n",
              " 'place of some \"w\"\\'s, etc.  This was a common practice of the day,',\n",
              " \"as print was still quite expensive, and they didn't want to spend\",\n",
              " 'more on a wider selection of characters than they had to.',\n",
              " '',\n",
              " 'You will find a lot of these kinds of \"errors\" in this text, as I',\n",
              " 'have mentioned in other times and places, many \"scholars\" have an',\n",
              " 'extreme attachment to these errors, and many have accorded them a',\n",
              " 'very high place in the \"canon\" of Shakespeare.  My father read an',\n",
              " 'assortment of these made available to him by Cambridge University',\n",
              " 'in England for several months in a glass room constructed for the',\n",
              " 'purpose.  To the best of my knowledge he read ALL those available',\n",
              " '. . .in great detail. . .and determined from the various changes,',\n",
              " 'that Shakespeare most likely did not write in nearly as many of a',\n",
              " 'variety of errors we credit him for, even though he was in/famous',\n",
              " 'for signing his name with several different spellings.',\n",
              " '',\n",
              " 'So, please take this into account when reading the comments below',\n",
              " 'made by our volunteer who prepared this file:  you may see errors',\n",
              " 'that are \"not\" errors. . . .',\n",
              " '',\n",
              " 'So. . .with this caveat. . .we have NOT changed the canon errors,',\n",
              " \"here is the Project Gutenberg Etext of Shakespeare's First Folio.\",\n",
              " '',\n",
              " 'Michael S. Hart',\n",
              " 'Project Gutenberg',\n",
              " 'Executive Director',\n",
              " '',\n",
              " '',\n",
              " '***',\n",
              " '',\n",
              " '',\n",
              " \"Scanner's Notes: What this is and isn't.  This is a copy of\",\n",
              " \"Shakespeare's first folio and it is as close as I can come in\",\n",
              " 'ASCII to the printed text.',\n",
              " '',\n",
              " 'The play Pericles, Prince of Tyre is missing from this edition',\n",
              " \"of the First Folio because it wasn't printed in the First Folio.\",\n",
              " 'The Sonnets and other poems of Shakespeare are also missing',\n",
              " 'because they also were not printed in the First Folio.',\n",
              " '',\n",
              " \"The elongated S's have been changed to small s's and the\",\n",
              " 'conjoined ae have been changed to ae.  I have left the spelling,',\n",
              " 'punctuation, capitalization as close as possible to the',\n",
              " 'printed text.  I have corrected some spelling mistakes (I have put',\n",
              " 'together a spelling dictionary devised from the spellings of the',\n",
              " \"Geneva Bible and Shakespeare's First Folio and have unified\",\n",
              " \"spellings according to this template), typo's and expanded\",\n",
              " 'abbreviations as I have come across them.  Everything within',\n",
              " \"brackets [] is what I have added.  So if you don't like that\",\n",
              " 'you can delete everything within the brackets if you want a',\n",
              " 'purer Shakespeare.',\n",
              " '',\n",
              " 'Another thing that you should be aware of is that there are textual',\n",
              " 'differences between various copies of the first folio.  So there may',\n",
              " 'be differences (other than what I have mentioned above) between',\n",
              " \"this and other first folio editions.  This is due to the printer's\",\n",
              " 'habit of setting the type and running off a number of copies and',\n",
              " 'then proofing the printed copy and correcting the type and then',\n",
              " \"continuing the printing run.  The proof run wasn't thrown away but\",\n",
              " 'incorporated into the printed copies.  This is just the way it is.',\n",
              " 'The text I have used was a composite of more than 30 different',\n",
              " \"First Folio editions' best pages.\",\n",
              " '',\n",
              " 'If you find any scanning errors, out and out typos, punctuation',\n",
              " 'errors, or if you disagree with my spelling choices please feel',\n",
              " 'free to email me those errors.  I wish to make this the best',\n",
              " 'etext possible.  My email address for right now are haradda@aol.com',\n",
              " 'and davidr@inconnect.com.  I hope that you enjoy this.',\n",
              " '',\n",
              " 'David Reed',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " \"Project Gutenberg's Etext of Shakespeare's First Folio/35 Plays\",\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " 'To the Reader.',\n",
              " '',\n",
              " 'This Figure, that thou here feest put,',\n",
              " 'It was for gentle Shakespeare cut:',\n",
              " 'Wherein the Grauer had a strife',\n",
              " 'with Naure, to out-doo the life:',\n",
              " 'O, could he but haue dravvne his vvit',\n",
              " 'As vvell in frasse, as he hath hit',\n",
              " 'Hisface; the Print vvould then surpasse',\n",
              " 'All, that vvas euer in frasse.',\n",
              " 'But, since he cannot, Reader, looke',\n",
              " 'Not on his picture, but his Booke.',\n",
              " '',\n",
              " 'B.I.',\n",
              " '',\n",
              " 'MR. William',\n",
              " 'SHAKESPEARES',\n",
              " 'Comedies,',\n",
              " 'Histories &',\n",
              " 'Tragedies,',\n",
              " 'Published according to the True Original Copies',\n",
              " 'London',\n",
              " 'Printed by Ifaac Iaggard, and Ed, Bount. 1623',\n",
              " '',\n",
              " '                    TO   THE   MOST   NOBLE',\n",
              " '                               AND',\n",
              " '                       INCOMPARABLE  PAIRE',\n",
              " '                           OF  BRETHREN',\n",
              " '',\n",
              " '                          WILLIAM',\n",
              " '         Earle of Pembroke,&c;.  Lord Chamberlaine to the',\n",
              " '                  Kings most Excellent Majesty.',\n",
              " '',\n",
              " '                              A N D',\n",
              " '',\n",
              " '                              PHILIP',\n",
              " '      Earle of  Montgomery,&c;.  Gentleman of his Majesties',\n",
              " '        Bed-Chamber.  Both Knights of the most Noble Order',\n",
              " '               of the Garter, and our singular good',\n",
              " '                            L O R D S',\n",
              " '',\n",
              " 'Right Honourable,',\n",
              " '',\n",
              " 'Whilst we studie to be thankful in our particular, for  the many',\n",
              " 'favors we have received from your L.L. we are falne upon the ill',\n",
              " 'fortune, to mingle two the most diverse things that can bee, feare,',\n",
              " 'and rashnesse; rashnesse in the enterprize, and feare of the',\n",
              " 'successe.  For, when we valew the places your H.H. sustaine, we',\n",
              " 'cannot but know their dignity greater, then to descend to the',\n",
              " 'reading of these trifles: and, while we name them trifles, we have',\n",
              " \"depriv'd our selves of the defence of our Dedication.  But since\",\n",
              " \"your L.L. have beene pleas'd to thinke these trifles some-thing,\",\n",
              " 'heeretofore; and have prosequuted both them, and their Authour',\n",
              " 'living, with so much favour: we hope, that (they out-living him,',\n",
              " 'and he not having the fate, common with some, to be exequutor to',\n",
              " 'his owne writings) you will use the like indulgence toward them,',\n",
              " 'you have done unto their parent. There is a great difference,',\n",
              " 'whether any Booke choose his Patrones, or finde them: This hath',\n",
              " 'done both.  For, so much were your L.L. likings of the severall',\n",
              " 'parts, when they were acted, as before they were published, the',\n",
              " \"Volume ask'd to be yours.  We have but collected them, and done\",\n",
              " 'an office to the dead, to procure his Orphanes, Guardians; without',\n",
              " 'ambition either of selfe-profit, or fame: onely to keepe the memory',\n",
              " 'of so worthy a Friend, & Fellow alive, as was our S H A K E S',\n",
              " 'P E A R E , by humble offer of his playes, to your most noble',\n",
              " 'patronage.  Wherein, as we have justly observed, no man to come',\n",
              " 'neere your L.L. but with a kind of religious addresse; it hath bin',\n",
              " 'the height of our care, who are the Presenters, to make the present',\n",
              " 'worthy of your H.H. by the perfection.  But, there we must also',\n",
              " 'crave our abilities to be considerd, my Lords.  We cannot go',\n",
              " 'beyond our owne powers.  Country hands reach foorth milke,',\n",
              " 'creame, fruites, or what they have : and many Nations (we have',\n",
              " 'heard) that had not gummes & incense, obtained their requests',\n",
              " 'with a leavened Cake.  It was no fault to approach their Gods, by',\n",
              " 'what meanes they could:  And the most, though meanest, of thins',\n",
              " 'are made more precious, when they are dedicated to Temples.  In',\n",
              " 'that name therefore, we most humbly consecrate to your H.H.',\n",
              " 'these remaines of your servant Shakespeare; that what delight is in',\n",
              " 'them, may be ever your L.L. the reputation his, & the faults ours, if',\n",
              " 'any be committed, by a payre so carefull to shew their gratitude',\n",
              " 'both to the living, and the dead, as is.',\n",
              " '',\n",
              " 'Your Lordshippes most bounden,',\n",
              " '',\n",
              " 'JOHN  HEMINGE.',\n",
              " 'HENRY  CONDELL.',\n",
              " '',\n",
              " '                 To the great Variety of Readers.',\n",
              " '',\n",
              " 'From the most able, to him that can but spell : There you are',\n",
              " \"number'd.  We had rather you were weighd.  Especially, when the\",\n",
              " 'fate of all Bookes depends upon your capacities  :  and not of your',\n",
              " 'heads alone, but of your purses.  Well !  It is now publique, & you',\n",
              " 'wil stand for your priviledges wee know  :  to read, and censure.',\n",
              " 'Do so, but buy it first.  That doth best commend a Booke, the',\n",
              " 'Stationer saies.  Then, how odde soever your braines be, or your',\n",
              " 'wisedomes, make your licence the same, and spare not.  Judge',\n",
              " \"your six-pen'orth, your shillings worth, your five shillings worth at\",\n",
              " 'a time, or higher, so you rise to the just rates, and welcome.  But,',\n",
              " 'whatever you do, Buy.  Censure will not drive a Trade, or make',\n",
              " 'the Jacke go.  And though you be a Magistrate of wit, and sit on',\n",
              " 'the Stage at Black-Friers, or the Cock-pit, to arraigne Playes dailie,',\n",
              " 'know, these Playes have had their triall alreadie, and stood out all',\n",
              " 'Appeales ; and do now come forth quitted rather by a Decree of',\n",
              " \"Court, then any purchas'd Letters of commendation.\",\n",
              " '',\n",
              " 'It had bene a thing, we confesse, worthie to have bene wished, that',\n",
              " \"the Author himselfe had liv'd to have set forth, and overseen his\",\n",
              " \"owne writings ; But since it hath bin ordain'd otherwise, and he by\",\n",
              " 'death departed from that right, we pray you do not envie his',\n",
              " 'Friends, the office of their care, and paine, to have collected &',\n",
              " \"publish'd them; and so to have publish'd them, as where (before)\",\n",
              " \"you were abus'd with diverse stolne, and surreptitious copies,\",\n",
              " 'maimed, and deformed by the frauds and stealthes of injurious',\n",
              " \"impostors, that expos'd them : even those, are now offer'd to your\",\n",
              " \"view cur'd, and perfect of their limbes; and all the rest, absolute in\",\n",
              " \"their numbers, as he conceived the'.  Who, as he was a happie\",\n",
              " 'imitator of Nature, was a most gentle expresser of it.  His mind',\n",
              " 'and hand went together: And what he thought, he uttered with that',\n",
              " 'easinesse, that wee have scarse received from him a blot in his',\n",
              " 'papers.  But it is not our province, who onely gather his works, and',\n",
              " 'give them you, to praise him.  It is yours that reade him.  And there',\n",
              " 'we hope, to your divers capacities, you will finde enough, both to',\n",
              " 'draw, and hold you : for his wit can no more lie hid, then it could',\n",
              " 'be lost.  Reade him, therefore; and againe, and againe : And if then',\n",
              " 'you doe not like him, surely you are in some manifest danger, not',\n",
              " 'to understand him.  And so we leave you to other of his Friends,',\n",
              " 'whom if you need, can bee your guides : if you neede them not,',\n",
              " 'you can leade your selves, and others.  And such Readers we wish',\n",
              " 'him.',\n",
              " '',\n",
              " 'John Heminge.',\n",
              " 'Henrie Condell.',\n",
              " '',\n",
              " '                           A CATALOGVE',\n",
              " '        of the Seuerall Comedies, Historie, and Tragedies',\n",
              " '                     contained in this Volume',\n",
              " '',\n",
              " '                            COMEDIES.',\n",
              " '',\n",
              " 'The Tempest.',\n",
              " 'The Two Gentlemen of Verona.',\n",
              " 'The Merry Wives of Windsor.',\n",
              " 'Measure for Measure.',\n",
              " 'The Comedy of Errours.',\n",
              " 'Much adoo about Nothing',\n",
              " 'Loves Labour lost.',\n",
              " 'Midsommer Nights Dreame.',\n",
              " 'The Merchant of Venice.',\n",
              " 'As you Like it.',\n",
              " 'The Taming of the Shrew.',\n",
              " 'All is well, that Ends well.',\n",
              " 'Twelfe-Night, or what you will.',\n",
              " 'The Winters Tale.',\n",
              " '',\n",
              " '                            HISTORIES.',\n",
              " '',\n",
              " 'The Life and Death of King John.',\n",
              " 'The Life & death of Richard the second.',\n",
              " 'The First part of King Henry the fourth.',\n",
              " 'The Second part of K. Henry the fourth.',\n",
              " 'The Life of King Henry the Fift.',\n",
              " 'The First part of King Henry the Sixt.',\n",
              " 'The Second part of King Hen. the Sixt.',\n",
              " 'The Third part of King Henry the Sixt.',\n",
              " 'The Life and Death of Richard the Third',\n",
              " 'The Life of King Henry the Eight.',\n",
              " '',\n",
              " '                            TRAGEDIES.',\n",
              " '',\n",
              " 'The Tragedy of Coriolanus.',\n",
              " 'Titus Andronicus.',\n",
              " 'Romeo and Juliet.',\n",
              " 'Timon of Athens.',\n",
              " 'The Life and death of Julius Caesar.',\n",
              " 'The Tragedy of Macbeth.',\n",
              " 'The Tragedy of Hamlet.',\n",
              " 'King Lear.',\n",
              " 'Othello, the Moore of Venice.',\n",
              " 'Anthony and Cleopater.',\n",
              " 'Cymbeline King of Britaine.',\n",
              " '',\n",
              " '                   To the memory of my beloved,',\n",
              " '                            The Author',\n",
              " '           MR. W I L L I A   M S H A K E S P E A R E :',\n",
              " '                              A N D',\n",
              " '                      what he hath left us.',\n",
              " '',\n",
              " 'To draw no envy (Shakespeare) on thy name,',\n",
              " 'Am I thus ample to thy Booke, and Fame;',\n",
              " 'While I confesse thy writings to be such,',\n",
              " 'As neither Man, nor Muse, can praise too much.',\n",
              " \"'Tis true, and all men's suffrage.  But these wayes\",\n",
              " 'Were not the paths I meant unto thy praise;',\n",
              " 'For seeliest Ignorance on these may light,',\n",
              " \"Which, when it sounds at best, but eccho's right;\",\n",
              " \"Or blinde Affection, which doth ne're advance\",\n",
              " 'The truth, but gropes, and urgeth all by chance;',\n",
              " 'Or crafty Malice, might pretend this praise,',\n",
              " \"And thine to ruine, where it seem'd to raise.\",\n",
              " 'These are, as some infamous Baud, or Whore,',\n",
              " 'Should praise a Matron.  What could hurt her more?',\n",
              " 'But thou art proofe against them, and indeed',\n",
              " \"Above th' ill fortune of them, or the need.\",\n",
              " 'I, therefore will begin.  Soule of the Age !',\n",
              " 'The applause ! delight ! the wonder of our Stage !',\n",
              " 'My Shakespeare, rise; I will not lodge thee by',\n",
              " 'Chaucer, or Spenser, or bid Beaumont lye',\n",
              " 'A little further, to make thee a roome :',\n",
              " 'Thou art a Moniment, without a tombe,',\n",
              " 'And art alive still, while thy Booke doth live,',\n",
              " 'And we have wits to read, and praise to give.',\n",
              " 'That I not mixe thee so, my braine excuses ;',\n",
              " \"I meane with great, but disproportion'd Muses :\",\n",
              " 'For, if I thought my judgement were of yeeres,',\n",
              " 'I should commit thee surely with thy peeres,',\n",
              " 'And tell, how farre thou dist our Lily out-shine,',\n",
              " 'Or sporting Kid or Marlowes mighty line.',\n",
              " 'And though thou hadst small Latine, and lesse Greeke,',\n",
              " 'From thence to honour thee, I would not seeke',\n",
              " \"For names; but call forth thund'ring  �schilus,\",\n",
              " 'Euripides, and Sophocles to vs,',\n",
              " 'Paccuvius, Accius, him of Cordova dead,',\n",
              " 'To life againe, to heare thy Buskin tread,',\n",
              " 'And shake a stage : Or, when thy sockes were on,',\n",
              " 'Leave thee alone, for the comparison',\n",
              " 'Of all, that insolent Greece, or haughtie Rome',\n",
              " 'Sent forth, or since did from their ashes come.',\n",
              " 'Triumph, my Britaine, thou hast one to showe,',\n",
              " 'To whom all scenes of Europe homage owe.',\n",
              " 'He was not of an age, but for all time !',\n",
              " 'And all the Muses still were in their prime,',\n",
              " 'When like Apollo he came forth to warme',\n",
              " 'Our eares, or like a Mercury to charme !',\n",
              " 'Nature her selfe was proud of his designes,',\n",
              " \"And joy'd to weare the dressing of his lines !\",\n",
              " 'Which were so richly spun, and woven so fit,',\n",
              " 'As, since, she will vouchsafe no other Wit.',\n",
              " 'The merry Greeke, tart Aristophanes,',\n",
              " 'Neat Terence, witty Plautus, now not',\n",
              " 'please;But antiquated, and deserted lye',\n",
              " 'As they were not of Natures family.',\n",
              " 'Yet must I not give Nature all: Thy Art,',\n",
              " 'My gentle Shakespeare, must enjoy a part;',\n",
              " 'For though the Poets matter, Nature be,',\n",
              " 'His Art doth give the fashion.  And, that he,',\n",
              " 'Who casts to write a living line, must sweat,',\n",
              " '(Such as thine are) and strike the second heat',\n",
              " 'Upon the Muses anvile : turne the same,',\n",
              " '(And himselfe with it) that he thinkes to frame;',\n",
              " 'Or for the lawrell, he may gaine a scorne,',\n",
              " \"For a good Poet's made, as well as borne.\",\n",
              " 'And such wert thou.  Looke how the fathers face',\n",
              " 'Lives in his issue, even so, the race',\n",
              " 'Of Shakespeares minde, and manners brightly shines',\n",
              " 'In his well toned, and true-filed lines :',\n",
              " 'In each of which, he seemes to shake a Lance,',\n",
              " \"As brandish't at the eyes of Ignorance.\",\n",
              " 'Sweet swan of Avon!  what a fight it were',\n",
              " 'To see thee in our waters yet appeare,',\n",
              " 'And make those flights upon the bankes of Thames,',\n",
              " 'That so did take Eliza, and our James !',\n",
              " 'But stay, I see thee in the Hemisphere',\n",
              " \"Advanc'd, and made a Constellation there !\",\n",
              " 'Shine forth, thou Starre of Poets, and with rage,',\n",
              " 'Or influence, chide, or cheere the drooping Stage;',\n",
              " \"Which, since thy flight fro' hence, hath mourn'd like night,\",\n",
              " 'And despaires day, but for thy Volumes light.',\n",
              " '',\n",
              " ' B E N:  J O N S O N.',\n",
              " '',\n",
              " '',\n",
              " '              Upon the Lines and Life of the Famous',\n",
              " '               Scenicke Poet, Master  W I L L I A M',\n",
              " '                      S H A K E S P E A R E',\n",
              " '',\n",
              " 'Those hands, which you so clapt, go now, and wring',\n",
              " 'You Britaines brave; for done are Shakespeares dayes :',\n",
              " 'His dayes are done, that made the dainty Playes,',\n",
              " \"Which made the Globe of heav'n and earth to ring.\",\n",
              " \"Dry'de is that veine, dry'd is the Thespian Spring,\",\n",
              " \"Turn'd all to teares, and Phoebus clouds his rayes :\",\n",
              " \"That corp's, that coffin now besticke those bayes,\",\n",
              " \"Which crown'd him Poet first, then Poets King.\",\n",
              " 'If Tragedies might any Prologue have,',\n",
              " 'All those he made, would scarse make a one to this :',\n",
              " 'Where Fame, now that he gone is to the grave',\n",
              " '(Deaths publique tyring-house) the Nuncius is,',\n",
              " 'For though his line of life went soone about,',\n",
              " 'The life yet of his lines shall never out.',\n",
              " '',\n",
              " ' H U G H   H O L L A N D.',\n",
              " '',\n",
              " '                          TO THE MEMORIE',\n",
              " '                 of the deceased Authour Maister',\n",
              " '                    W.  S H A K E S P E A R E.',\n",
              " '',\n",
              " 'Shake-speare, at length thy pious fellowes give',\n",
              " 'The world thy Workes : thy Workes, by which, out-live',\n",
              " 'Thy Tombe, thy name must when that stone is rent,',\n",
              " 'And Time dissolves thy Stratford Moniment,',\n",
              " 'Here we alive shall view thee still.  This Booke,',\n",
              " 'When Brasse and Marble fade, shall make thee looke',\n",
              " 'Fresh to all Ages: when Posteritie',\n",
              " \"Shall loath what's new, thinke all is prodegie\",\n",
              " \"That is not Shake-speares; ev'ry Line, each Verse\",\n",
              " 'Here shall revive, redeeme thee from thy Herse.',\n",
              " 'Nor Fire, nor cankring Age, as Naso said,',\n",
              " 'Of his, thy wit-fraught Booke shall once invade.',\n",
              " \"Nor shall I e're beleeve, or thinke thee dead.\",\n",
              " '(Though mist) untill our bankrout Stage be sped',\n",
              " \"(Imposible) with some new straine t'out-do\",\n",
              " 'Passions of Juliet, and her Romeo ;',\n",
              " 'Or till I heare a Scene more nobly take,',\n",
              " 'Then when thy half-Sword parlying Romans spake.',\n",
              " 'Till these, till any of thy Volumes rest',\n",
              " 'Shall with more fire, more feeling be exprest,',\n",
              " 'Be sure, our Shake-speare, thou canst never dye,',\n",
              " \"But crown'd with Lawrell, live eternally.\",\n",
              " '',\n",
              " ' L.   Digges.',\n",
              " '',\n",
              " '               To the memorie of M.W.Shakes-speare.',\n",
              " '',\n",
              " \"WEE wondred (Shake-speare) that thou went'st so soone\",\n",
              " 'From the Worlds-Stage, to the Graves-Tyring-roome.',\n",
              " 'Wee thought thee dead, but this thy printed worth,',\n",
              " \"Tels thy Spectators, that thou went'st but forth\",\n",
              " 'To enter with applause.  An Actors Art,',\n",
              " 'Can dye, and live, to acte a second part.',\n",
              " \"That's but an Exit of Mortalitie;\",\n",
              " 'This, a Re-entrance to a Plaudite.',\n",
              " '',\n",
              " ' J.   M.',\n",
              " '',\n",
              " '                The Workes of William Shakespeare,',\n",
              " '           containing all his Comedies, Histories, and',\n",
              " '      Tragedies: Truely set forth, according to their first',\n",
              " '                        O R I G I N A L L',\n",
              " '',\n",
              " '     The Names of the Principall Actorsin all these Playes.',\n",
              " '',\n",
              " 'William Shakespeare.',\n",
              " 'Richard Burbadge.',\n",
              " 'John Hemmings.',\n",
              " 'Augustine Phillips.',\n",
              " 'William Kempt.',\n",
              " 'Thomas Poope.',\n",
              " 'George Bryan.',\n",
              " 'Henry Condell.',\n",
              " 'William Slye.',\n",
              " 'Richard Cowly.',\n",
              " 'John Lowine.',\n",
              " 'Samuell Crosse.',\n",
              " 'Alexander Cooke.',\n",
              " 'Samuel Gilburne.',\n",
              " 'Robert Armin.',\n",
              " 'William Ostler.',\n",
              " 'Nathan Field.',\n",
              " 'John Underwood.',\n",
              " 'Nicholas Tooley.',\n",
              " 'William Ecclestone.',\n",
              " 'Joseph Taylor.',\n",
              " 'Robert Benfield.',\n",
              " 'Robert Goughe.',\n",
              " 'Richard Robinson.',\n",
              " 'John Shancke.',\n",
              " 'John Rice.',\n",
              " '',\n",
              " 'The Tempest',\n",
              " '',\n",
              " 'Actus primus, Scena prima.',\n",
              " '',\n",
              " 'A tempestuous noise of Thunder and Lightning heard: Enter a',\n",
              " 'Ship-master,',\n",
              " 'and a Boteswaine.',\n",
              " '',\n",
              " '  Master. Bote-swaine.',\n",
              " '',\n",
              " '  Botes. Heere Master: What cheere?',\n",
              " '',\n",
              " \"  Mast. Good: Speake to th' Mariners: fall\",\n",
              " \"too't, yarely, or we run our selues a ground,\",\n",
              " 'bestirre, bestirre.',\n",
              " '',\n",
              " 'Enter.',\n",
              " '',\n",
              " 'Enter Mariners.',\n",
              " '',\n",
              " '  Botes. Heigh my hearts, cheerely, cheerely my harts:',\n",
              " \"yare, yare: Take in the toppe-sale: Tend to th' Masters\",\n",
              " 'whistle: Blow till thou burst thy winde, if roome enough.',\n",
              " '',\n",
              " 'Enter Alonso, Sebastian, Anthonio, Ferdinando, Gonzalo, and',\n",
              " 'others.',\n",
              " '',\n",
              " \"  Alon. Good Boteswaine haue care: where's the Master?\",\n",
              " 'Play the men.',\n",
              " '',\n",
              " '  Botes. I pray now keepe below.',\n",
              " '',\n",
              " '  Anth. Where is the Master, Boson?',\n",
              " '',\n",
              " '  Botes. Do you not heare him? you marre our labour,',\n",
              " 'Keepe your Cabines: you do assist the storme.',\n",
              " '',\n",
              " '  Gonz. Nay, good be patient.',\n",
              " '',\n",
              " '  Botes. When the Sea is: hence, what cares these roarers',\n",
              " 'for the name of King? to Cabine; silence: trouble vs not.',\n",
              " '',\n",
              " '  Gon. Good, yet remember whom thou hast aboord.',\n",
              " '',\n",
              " '  Botes. None that I more loue then my selfe. You are',\n",
              " 'a Counsellor, if you can command these Elements to silence,',\n",
              " 'and worke the peace of the present, wee will not',\n",
              " 'hand a rope more, vse your authoritie: If you cannot,',\n",
              " \"giue thankes you haue liu'd so long, and make your\",\n",
              " 'selfe readie in your Cabine for the mischance of the',\n",
              " 'houre, if it so hap. Cheerely good hearts: out of our',\n",
              " 'way I say.',\n",
              " '',\n",
              " 'Enter.',\n",
              " '',\n",
              " '  Gon. I haue great comfort from this fellow: methinks',\n",
              " 'he hath no drowning marke vpon him, his complexion',\n",
              " 'is perfect Gallowes: stand fast good Fate to his hanging,',\n",
              " 'make the rope of his destiny our cable, for our',\n",
              " 'owne doth little aduantage: If he be not borne to bee',\n",
              " \"hang'd, our case is miserable.\",\n",
              " '',\n",
              " 'Enter.',\n",
              " '',\n",
              " 'Enter Boteswaine',\n",
              " '',\n",
              " '  Botes. Downe with the top-Mast: yare, lower, lower,',\n",
              " 'bring her to Try with Maine-course. A plague -',\n",
              " '',\n",
              " 'A cry within. Enter Sebastian, Anthonio & Gonzalo.',\n",
              " '',\n",
              " 'vpon this howling: they are lowder then the weather,',\n",
              " 'or our office: yet againe? What do you heere? Shal we',\n",
              " 'giue ore and drowne, haue you a minde to sinke?',\n",
              " '',\n",
              " \"  Sebas. A poxe o'your throat, you bawling, blasphemous\",\n",
              " 'incharitable Dog.',\n",
              " '',\n",
              " '  Botes. Worke you then.',\n",
              " '  Anth. Hang cur, hang, you whoreson insolent Noyse-maker,',\n",
              " 'we are lesse afraid to be drownde, then thou art.',\n",
              " '',\n",
              " \"  Gonz. I'le warrant him for drowning, though the\",\n",
              " 'Ship were no stronger then a Nutt-shell, and as leaky as',\n",
              " 'an vnstanched wench.',\n",
              " '',\n",
              " '  Botes. Lay her a hold, a hold, set her two courses off',\n",
              " 'to Sea againe, lay her off.',\n",
              " '',\n",
              " 'Enter Mariners wet.',\n",
              " '',\n",
              " '  Mari. All lost, to prayers, to prayers, all lost.',\n",
              " '',\n",
              " '  Botes. What must our mouths be cold?',\n",
              " '',\n",
              " \"  Gonz. The King, and Prince, at prayers, let's assist them,\",\n",
              " 'for our case is as theirs',\n",
              " '',\n",
              " \"   Sebas. I'am out of patience\",\n",
              " '',\n",
              " '   An. We are meerly cheated of our liues by drunkards,',\n",
              " 'This wide-chopt-rascall, would thou mightst lye drowning',\n",
              " 'the washing of ten Tides',\n",
              " '',\n",
              " \"   Gonz. Hee'l be hang'd yet,\",\n",
              " 'Though euery drop of water sweare against it,',\n",
              " 'And gape at widst to glut him.',\n",
              " '',\n",
              " 'A confused noyse within.',\n",
              " '',\n",
              " 'Mercy on vs.',\n",
              " 'We split, we split, Farewell my wife, and children,',\n",
              " 'Farewell brother: we split, we split, we split',\n",
              " '',\n",
              " \"   Anth. Let's all sinke with' King\",\n",
              " '',\n",
              " \"  Seb. Let's take leaue of him.\",\n",
              " '',\n",
              " 'Enter.',\n",
              " '',\n",
              " '  Gonz. Now would I giue a thousand furlongs of Sea,',\n",
              " 'for an Acre of barren ground: Long heath, Browne',\n",
              " 'firrs, any thing; the wills aboue be done, but I would',\n",
              " 'faine dye a dry death.',\n",
              " '',\n",
              " 'Enter.',\n",
              " '',\n",
              " '',\n",
              " 'Scena Secunda.',\n",
              " '',\n",
              " '',\n",
              " 'Enter Prospero and Miranda.',\n",
              " '',\n",
              " '  Mira. If by your Art (my deerest father) you haue',\n",
              " 'Put the wild waters in this Rore; alay them:',\n",
              " 'The skye it seemes would powre down stinking pitch,',\n",
              " \"But that the Sea, mounting to th' welkins cheeke,\",\n",
              " 'Dashes the fire out. Oh! I haue suffered',\n",
              " 'With those that I saw suffer: A braue vessell',\n",
              " '(Who had no doubt some noble creature in her)',\n",
              " \"Dash'd all to peeces: O the cry did knocke\",\n",
              " \"Against my very heart: poore soules, they perish'd.\",\n",
              " 'Had I byn any God of power, I would',\n",
              " 'Haue suncke the Sea within the Earth, or ere',\n",
              " \"It should the good Ship so haue swallow'd, and\",\n",
              " 'The fraughting Soules within her',\n",
              " '',\n",
              " '   Pros. Be collected,',\n",
              " 'No more amazement: Tell your pitteous heart',\n",
              " \"there's no harme done\",\n",
              " '',\n",
              " '   Mira. O woe, the day',\n",
              " '',\n",
              " '   Pros. No harme:',\n",
              " 'I haue done nothing, but in care of thee',\n",
              " '(Of thee my deere one; thee my daughter) who',\n",
              " 'Art ignorant of what thou art. naught knowing',\n",
              " 'Of whence I am: nor that I am more better',\n",
              " 'Then Prospero, Master of a full poore cell,',\n",
              " 'And thy no greater Father',\n",
              " '',\n",
              " '   Mira. More to know',\n",
              " 'Did neuer medle with my thoughts',\n",
              " '',\n",
              " \"   Pros. 'Tis time\",\n",
              " 'I should informe thee farther: Lend thy hand',\n",
              " 'And plucke my Magick garment from me: So,',\n",
              " 'Lye there my Art: wipe thou thine eyes, haue comfort,',\n",
              " \"The direfull spectacle of the wracke which touch'd\",\n",
              " 'The very vertue of compassion in thee:',\n",
              " 'I haue with such prouision in mine Art',\n",
              " 'So safely ordered, that there is no soule',\n",
              " 'No not so much perdition as an hayre',\n",
              " 'Betid to any creature in the vessell',\n",
              " \"Which thou heardst cry, which thou saw'st sinke: Sit downe,\",\n",
              " 'For thou must now know farther',\n",
              " '',\n",
              " '   Mira. You haue often',\n",
              " 'Begun to tell me what I am, but stopt',\n",
              " 'And left me to a bootelesse Inquisition,',\n",
              " 'Concluding, stay: not yet',\n",
              " '',\n",
              " \"   Pros. The howr's now come\",\n",
              " 'The very minute byds thee ope thine eare,',\n",
              " 'Obey, and be attentiue. Canst thou remember',\n",
              " 'A time before we came vnto this Cell?',\n",
              " \"I doe not thinke thou canst, for then thou was't not\",\n",
              " 'Out three yeeres old',\n",
              " '',\n",
              " '   Mira. Certainely Sir, I can',\n",
              " '',\n",
              " '   Pros. By what? by any other house, or person?',\n",
              " 'Of any thing the Image, tell me, that',\n",
              " 'Hath kept with thy remembrance',\n",
              " '',\n",
              " \"   Mira. 'Tis farre off:\",\n",
              " 'And rather like a dreame, then an assurance',\n",
              " 'That my remembrance warrants: Had I not',\n",
              " 'Fowre, or fiue women once, that tended me?',\n",
              " '',\n",
              " '  Pros. Thou hadst; and more Miranda: But how is it',\n",
              " 'That this liues in thy minde? What seest thou els',\n",
              " 'In the dark-backward and Abisme of Time?',\n",
              " \"Yf thou remembrest ought ere thou cam'st here,\",\n",
              " \"How thou cam'st here thou maist\",\n",
              " '',\n",
              " '   Mira. But that I doe not',\n",
              " '',\n",
              " '   Pros. Twelue yere since (Miranda) twelue yere since,',\n",
              " 'Thy father was the Duke of Millaine and',\n",
              " 'A Prince of power:',\n",
              " '',\n",
              " '  Mira. Sir, are not you my Father?',\n",
              " '',\n",
              " '  Pros. Thy Mother was a peece of vertue, and',\n",
              " 'She said thou wast my daughter; and thy father',\n",
              " 'Was Duke of Millaine, and his onely heire,',\n",
              " 'And Princesse; no worse Issued',\n",
              " '',\n",
              " '   Mira. O the heauens,',\n",
              " 'What fowle play had we, that we came from thence?',\n",
              " \"Or blessed was't we did?\",\n",
              " '',\n",
              " '  Pros. Both, both my Girle.',\n",
              " \"By fowle-play (as thou saist) were we heau'd thence,\",\n",
              " 'But blessedly holpe hither',\n",
              " '',\n",
              " '   Mira. O my heart bleedes',\n",
              " \"To thinke oth' teene that I haue turn'd you to,\",\n",
              " 'Which is from my remembrance, please you, farther;',\n",
              " '',\n",
              " \"  Pros. My brother and thy vncle, call'd Anthonio:\",\n",
              " 'I pray thee marke me, that a brother should',\n",
              " 'Be so perfidious: he, whom next thy selfe',\n",
              " \"Of all the world I lou'd, and to him put\",\n",
              " 'The mannage of my state, as at that time',\n",
              " 'Through all the signories it was the first,',\n",
              " 'And Prospero, the prime Duke, being so reputed',\n",
              " 'In dignity; and for the liberall Artes,',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cF37-sAMV-PT"
      },
      "source": [
        "rdd=words.flatMap(lambda x : x.split(\" \")).map(lambda x : (x,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mt2mLZDBWYw7",
        "outputId": "7a65491d-f24e-47c0-acc8-d73187ff4f95"
      },
      "source": [
        "rdd.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Project', 1),\n",
              " (\"Gutenberg's\", 1),\n",
              " ('Etext', 1),\n",
              " ('of', 1),\n",
              " (\"Shakespeare's\", 1),\n",
              " ('First', 1),\n",
              " ('Folio/35', 1),\n",
              " ('Plays', 1),\n",
              " ('This', 1),\n",
              " ('is', 1),\n",
              " ('our', 1),\n",
              " ('3rd', 1),\n",
              " ('edition', 1),\n",
              " ('of', 1),\n",
              " ('most', 1),\n",
              " ('of', 1),\n",
              " ('these', 1),\n",
              " ('plays.', 1),\n",
              " ('', 1),\n",
              " ('See', 1),\n",
              " ('the', 1),\n",
              " ('index.', 1),\n",
              " ('', 1),\n",
              " ('', 1),\n",
              " ('Copyright', 1),\n",
              " ('laws', 1),\n",
              " ('are', 1),\n",
              " ('changing', 1),\n",
              " ('all', 1),\n",
              " ('over', 1),\n",
              " ('the', 1),\n",
              " ('world,', 1),\n",
              " ('be', 1),\n",
              " ('sure', 1),\n",
              " ('to', 1),\n",
              " ('check', 1),\n",
              " ('the', 1),\n",
              " ('copyright', 1),\n",
              " ('laws', 1),\n",
              " ('for', 1),\n",
              " ('your', 1),\n",
              " ('country', 1),\n",
              " ('before', 1),\n",
              " ('posting', 1),\n",
              " ('these', 1),\n",
              " ('files!!', 1),\n",
              " ('', 1),\n",
              " ('Please', 1),\n",
              " ('take', 1),\n",
              " ('a', 1),\n",
              " ('look', 1),\n",
              " ('at', 1),\n",
              " ('the', 1),\n",
              " ('important', 1),\n",
              " ('information', 1),\n",
              " ('in', 1),\n",
              " ('this', 1),\n",
              " ('header.', 1),\n",
              " ('We', 1),\n",
              " ('encourage', 1),\n",
              " ('you', 1),\n",
              " ('to', 1),\n",
              " ('keep', 1),\n",
              " ('this', 1),\n",
              " ('file', 1),\n",
              " ('on', 1),\n",
              " ('your', 1),\n",
              " ('own', 1),\n",
              " ('disk,', 1),\n",
              " ('keeping', 1),\n",
              " ('an', 1),\n",
              " ('electronic', 1),\n",
              " ('path', 1),\n",
              " ('open', 1),\n",
              " ('for', 1),\n",
              " ('the', 1),\n",
              " ('next', 1),\n",
              " ('readers.', 1),\n",
              " ('', 1),\n",
              " ('Do', 1),\n",
              " ('not', 1),\n",
              " ('remove', 1),\n",
              " ('this.', 1),\n",
              " ('', 1),\n",
              " ('', 1),\n",
              " ('**Welcome', 1),\n",
              " ('To', 1),\n",
              " ('The', 1),\n",
              " ('World', 1),\n",
              " ('of', 1),\n",
              " ('Free', 1),\n",
              " ('Plain', 1),\n",
              " ('Vanilla', 1),\n",
              " ('Electronic', 1),\n",
              " ('Texts**', 1),\n",
              " ('', 1),\n",
              " ('**Etexts', 1),\n",
              " ('Readable', 1),\n",
              " ('By', 1),\n",
              " ('Both', 1),\n",
              " ('Humans', 1),\n",
              " ('and', 1),\n",
              " ('By', 1),\n",
              " ('Computers,', 1),\n",
              " ('Since', 1),\n",
              " ('1971**', 1),\n",
              " ('', 1),\n",
              " ('*These', 1),\n",
              " ('Etexts', 1),\n",
              " ('Prepared', 1),\n",
              " ('By', 1),\n",
              " ('Hundreds', 1),\n",
              " ('of', 1),\n",
              " ('Volunteers', 1),\n",
              " ('and', 1),\n",
              " ('Donations*', 1),\n",
              " ('', 1),\n",
              " ('Information', 1),\n",
              " ('on', 1),\n",
              " ('contacting', 1),\n",
              " ('Project', 1),\n",
              " ('Gutenberg', 1),\n",
              " ('to', 1),\n",
              " ('get', 1),\n",
              " ('Etexts,', 1),\n",
              " ('and', 1),\n",
              " ('further', 1),\n",
              " ('information', 1),\n",
              " ('is', 1),\n",
              " ('included', 1),\n",
              " ('below.', 1),\n",
              " ('', 1),\n",
              " ('We', 1),\n",
              " ('need', 1),\n",
              " ('your', 1),\n",
              " ('donations.', 1),\n",
              " ('', 1),\n",
              " ('', 1),\n",
              " ('The', 1),\n",
              " ('First', 1),\n",
              " ('Folio', 1),\n",
              " ('[35', 1),\n",
              " ('Plays]', 1),\n",
              " ('', 1),\n",
              " ('by', 1),\n",
              " ('William', 1),\n",
              " ('Shakespeare', 1),\n",
              " ('', 1),\n",
              " ('July,', 1),\n",
              " ('2000', 1),\n",
              " ('', 1),\n",
              " ('[Etext', 1),\n",
              " ('#2270]', 1),\n",
              " ('', 1),\n",
              " ('', 1),\n",
              " ('Project', 1),\n",
              " (\"Gutenberg's\", 1),\n",
              " ('Etext', 1),\n",
              " ('of', 1),\n",
              " (\"Shakespeare's\", 1),\n",
              " ('First', 1),\n",
              " ('Folio/35', 1),\n",
              " ('Plays', 1),\n",
              " ('*****This', 1),\n",
              " ('file', 1),\n",
              " ('should', 1),\n",
              " ('be', 1),\n",
              " ('named', 1),\n",
              " ('00ws110.txt', 1),\n",
              " ('or', 1),\n",
              " ('00ws110.zip******', 1),\n",
              " ('', 1),\n",
              " ('Corrected', 1),\n",
              " ('EDITIONS', 1),\n",
              " ('of', 1),\n",
              " ('our', 1),\n",
              " ('etexts', 1),\n",
              " ('get', 1),\n",
              " ('a', 1),\n",
              " ('new', 1),\n",
              " ('NUMBER,', 1),\n",
              " ('00ws111.txt', 1),\n",
              " ('VERSIONS', 1),\n",
              " ('based', 1),\n",
              " ('on', 1),\n",
              " ('separate', 1),\n",
              " ('sources', 1),\n",
              " ('get', 1),\n",
              " ('new', 1),\n",
              " ('LETTER,', 1),\n",
              " ('00ws110a.txt', 1),\n",
              " ('', 1),\n",
              " ('', 1),\n",
              " ('Project', 1),\n",
              " ('Gutenberg', 1),\n",
              " ('Etexts', 1),\n",
              " ('are', 1),\n",
              " ('usually', 1),\n",
              " ('created', 1),\n",
              " ('from', 1),\n",
              " ('multiple', 1),\n",
              " ('editions,', 1),\n",
              " ('all', 1),\n",
              " ('of', 1),\n",
              " ('which', 1),\n",
              " ('are', 1),\n",
              " ('in', 1),\n",
              " ('the', 1),\n",
              " ('Public', 1),\n",
              " ('Domain', 1),\n",
              " ('in', 1),\n",
              " ('the', 1),\n",
              " ('United', 1),\n",
              " ('States,', 1),\n",
              " ('unless', 1),\n",
              " ('a', 1),\n",
              " ('copyright', 1),\n",
              " ('notice', 1),\n",
              " ('is', 1),\n",
              " ('included.', 1),\n",
              " ('', 1),\n",
              " ('Therefore,', 1),\n",
              " ('we', 1),\n",
              " ('usually', 1),\n",
              " ('do', 1),\n",
              " ('NOT', 1),\n",
              " ('keep', 1),\n",
              " ('any', 1),\n",
              " ('of', 1),\n",
              " ('these', 1),\n",
              " ('books', 1),\n",
              " ('in', 1),\n",
              " ('compliance', 1),\n",
              " ('with', 1),\n",
              " ('any', 1),\n",
              " ('particular', 1),\n",
              " ('paper', 1),\n",
              " ('edition.', 1),\n",
              " ('', 1),\n",
              " ('', 1),\n",
              " ('We', 1),\n",
              " ('are', 1),\n",
              " ('now', 1),\n",
              " ('trying', 1),\n",
              " ('to', 1),\n",
              " ('release', 1),\n",
              " ('all', 1),\n",
              " ('our', 1),\n",
              " ('books', 1),\n",
              " ('one', 1),\n",
              " ('month', 1),\n",
              " ('in', 1),\n",
              " ('advance', 1),\n",
              " ('of', 1),\n",
              " ('the', 1),\n",
              " ('official', 1),\n",
              " ('release', 1),\n",
              " ('dates,', 1),\n",
              " ('leaving', 1),\n",
              " ('time', 1),\n",
              " ('for', 1),\n",
              " ('better', 1),\n",
              " ('editing.', 1),\n",
              " ('', 1),\n",
              " ('Please', 1),\n",
              " ('note:', 1),\n",
              " ('', 1),\n",
              " ('neither', 1),\n",
              " ('this', 1),\n",
              " ('list', 1),\n",
              " ('nor', 1),\n",
              " ('its', 1),\n",
              " ('contents', 1),\n",
              " ('are', 1),\n",
              " ('final', 1),\n",
              " ('till', 1),\n",
              " ('midnight', 1),\n",
              " ('of', 1),\n",
              " ('the', 1),\n",
              " ('last', 1),\n",
              " ('day', 1),\n",
              " ('of', 1),\n",
              " ('the', 1),\n",
              " ('month', 1),\n",
              " ('of', 1),\n",
              " ('any', 1),\n",
              " ('such', 1),\n",
              " ('announcement.', 1),\n",
              " ('The', 1),\n",
              " ('official', 1),\n",
              " ('release', 1),\n",
              " ('date', 1),\n",
              " ('of', 1),\n",
              " ('all', 1),\n",
              " ('Project', 1),\n",
              " ('Gutenberg', 1),\n",
              " ('Etexts', 1),\n",
              " ('is', 1),\n",
              " ('at', 1),\n",
              " ('Midnight,', 1),\n",
              " ('Central', 1),\n",
              " ('Time,', 1),\n",
              " ('of', 1),\n",
              " ('the', 1),\n",
              " ('last', 1),\n",
              " ('day', 1),\n",
              " ('of', 1),\n",
              " ('the', 1),\n",
              " ('stated', 1),\n",
              " ('month.', 1),\n",
              " ('', 1),\n",
              " ('A', 1),\n",
              " ('preliminary', 1),\n",
              " ('version', 1),\n",
              " ('may', 1),\n",
              " ('often', 1),\n",
              " ('be', 1),\n",
              " ('posted', 1),\n",
              " ('for', 1),\n",
              " ('suggestion,', 1),\n",
              " ('comment', 1),\n",
              " ('and', 1),\n",
              " ('editing', 1),\n",
              " ('by', 1),\n",
              " ('those', 1),\n",
              " ('who', 1),\n",
              " ('wish', 1),\n",
              " ('to', 1),\n",
              " ('do', 1),\n",
              " ('so.', 1),\n",
              " ('', 1),\n",
              " ('To', 1),\n",
              " ('be', 1),\n",
              " ('sure', 1),\n",
              " ('you', 1),\n",
              " ('have', 1),\n",
              " ('an', 1),\n",
              " ('up', 1),\n",
              " ('to', 1),\n",
              " ('date', 1),\n",
              " ('first', 1),\n",
              " ('edition', 1),\n",
              " ('[xxxxx10x.xxx]', 1),\n",
              " ('please', 1),\n",
              " ('check', 1),\n",
              " ('file', 1),\n",
              " ('sizes', 1),\n",
              " ('in', 1),\n",
              " ('the', 1),\n",
              " ('first', 1),\n",
              " ('week', 1),\n",
              " ('of', 1),\n",
              " ('the', 1),\n",
              " ('next', 1),\n",
              " ('month.', 1),\n",
              " ('', 1),\n",
              " ('Since', 1),\n",
              " ('our', 1),\n",
              " ('ftp', 1),\n",
              " ('program', 1),\n",
              " ('has', 1),\n",
              " ('a', 1),\n",
              " ('bug', 1),\n",
              " ('in', 1),\n",
              " ('it', 1),\n",
              " ('that', 1),\n",
              " ('scrambles', 1),\n",
              " ('the', 1),\n",
              " ('date', 1),\n",
              " ('[tried', 1),\n",
              " ('to', 1),\n",
              " ('fix', 1),\n",
              " ('and', 1),\n",
              " ('failed]', 1),\n",
              " ('a', 1),\n",
              " ('look', 1),\n",
              " ('at', 1),\n",
              " ('the', 1),\n",
              " ('file', 1),\n",
              " ('size', 1),\n",
              " ('will', 1),\n",
              " ('have', 1),\n",
              " ('to', 1),\n",
              " ('do,', 1),\n",
              " ('but', 1),\n",
              " ('we', 1),\n",
              " ('will', 1),\n",
              " ('try', 1),\n",
              " ('to', 1),\n",
              " ('see', 1),\n",
              " ('a', 1),\n",
              " ('new', 1),\n",
              " ('copy', 1),\n",
              " ('has', 1),\n",
              " ('at', 1),\n",
              " ('least', 1),\n",
              " ('one', 1),\n",
              " ('byte', 1),\n",
              " ('more', 1),\n",
              " ('or', 1),\n",
              " ('less.', 1),\n",
              " ('', 1),\n",
              " ('', 1),\n",
              " ('Information', 1),\n",
              " ('about', 1),\n",
              " ('Project', 1),\n",
              " ('Gutenberg', 1),\n",
              " ('(one', 1),\n",
              " ('page)', 1),\n",
              " ('', 1),\n",
              " ('We', 1),\n",
              " ('produce', 1),\n",
              " ('about', 1),\n",
              " ('two', 1),\n",
              " ('million', 1),\n",
              " ('dollars', 1),\n",
              " ('for', 1),\n",
              " ('each', 1),\n",
              " ('hour', 1),\n",
              " ('we', 1),\n",
              " ('work.', 1),\n",
              " ('', 1),\n",
              " ('The', 1),\n",
              " ('time', 1),\n",
              " ('it', 1),\n",
              " ('takes', 1),\n",
              " ('us,', 1),\n",
              " ('a', 1),\n",
              " ('rather', 1),\n",
              " ('conservative', 1),\n",
              " ('estimate,', 1),\n",
              " ('is', 1),\n",
              " ('fifty', 1),\n",
              " ('hours', 1),\n",
              " ('to', 1),\n",
              " ('get', 1),\n",
              " ('any', 1),\n",
              " ('etext', 1),\n",
              " ('selected,', 1),\n",
              " ('entered,', 1),\n",
              " ('proofread,', 1),\n",
              " ('edited,', 1),\n",
              " ('copyright', 1),\n",
              " ('searched', 1),\n",
              " ('and', 1),\n",
              " ('analyzed,', 1),\n",
              " ('the', 1),\n",
              " ('copyright', 1),\n",
              " ('letters', 1),\n",
              " ('written,', 1),\n",
              " ('etc.', 1),\n",
              " ('', 1),\n",
              " ('This', 1),\n",
              " ('projected', 1),\n",
              " ('audience', 1),\n",
              " ('is', 1),\n",
              " ('one', 1),\n",
              " ('hundred', 1),\n",
              " ('million', 1),\n",
              " ('readers.', 1),\n",
              " ('', 1),\n",
              " ('If', 1),\n",
              " ('our', 1),\n",
              " ('value', 1),\n",
              " ('per', 1),\n",
              " ('text', 1),\n",
              " ('is', 1),\n",
              " ('nominally', 1),\n",
              " ('estimated', 1),\n",
              " ('at', 1),\n",
              " ('one', 1),\n",
              " ('dollar', 1),\n",
              " ('then', 1),\n",
              " ('we', 1),\n",
              " ('produce', 1),\n",
              " ('$2', 1),\n",
              " ('million', 1),\n",
              " ('dollars', 1),\n",
              " ('per', 1),\n",
              " ('hour', 1),\n",
              " ('this', 1),\n",
              " ('year', 1),\n",
              " ('as', 1),\n",
              " ('we', 1),\n",
              " ('release', 1),\n",
              " ('thirty-six', 1),\n",
              " ('text', 1),\n",
              " ('files', 1),\n",
              " ('per', 1),\n",
              " ('month,', 1),\n",
              " ('or', 1),\n",
              " ('432', 1),\n",
              " ('more', 1),\n",
              " ('Etexts', 1),\n",
              " ('in', 1),\n",
              " ('1999', 1),\n",
              " ('for', 1),\n",
              " ('a', 1),\n",
              " ('total', 1),\n",
              " ('of', 1),\n",
              " ('2000+', 1),\n",
              " ('If', 1),\n",
              " ('these', 1),\n",
              " ('reach', 1),\n",
              " ('just', 1),\n",
              " ('10%', 1),\n",
              " ('of', 1),\n",
              " ('the', 1),\n",
              " ('computerized', 1),\n",
              " ('population,', 1),\n",
              " ('then', 1),\n",
              " ('the', 1),\n",
              " ('total', 1),\n",
              " ('should', 1),\n",
              " ('reach', 1),\n",
              " ('over', 1),\n",
              " ('200', 1),\n",
              " ('billion', 1),\n",
              " ('Etexts', 1),\n",
              " ('given', 1),\n",
              " ('away', 1),\n",
              " ('this', 1),\n",
              " ('year.', 1),\n",
              " ('', 1),\n",
              " ('The', 1),\n",
              " ('Goal', 1),\n",
              " ('of', 1),\n",
              " ('Project', 1),\n",
              " ('Gutenberg', 1),\n",
              " ('is', 1),\n",
              " ('to', 1),\n",
              " ('Give', 1),\n",
              " ('Away', 1),\n",
              " ('One', 1),\n",
              " ('Trillion', 1),\n",
              " ('Etext', 1),\n",
              " ('Files', 1),\n",
              " ('by', 1),\n",
              " ('December', 1),\n",
              " ('31,', 1),\n",
              " ('2001.', 1),\n",
              " ('', 1),\n",
              " ('[10,000', 1),\n",
              " ('x', 1),\n",
              " ('100,000,000', 1),\n",
              " ('=', 1),\n",
              " ('1', 1),\n",
              " ('Trillion]', 1),\n",
              " ('This', 1),\n",
              " ('is', 1),\n",
              " ('ten', 1),\n",
              " ('thousand', 1),\n",
              " ('titles', 1),\n",
              " ('each', 1),\n",
              " ('to', 1),\n",
              " ('one', 1),\n",
              " ('hundred', 1),\n",
              " ('million', 1),\n",
              " ('readers,', 1),\n",
              " ('which', 1),\n",
              " ('is', 1),\n",
              " ('only', 1),\n",
              " ('~5%', 1),\n",
              " ('of', 1),\n",
              " ('the', 1),\n",
              " ('present', 1),\n",
              " ('number', 1),\n",
              " ('of', 1),\n",
              " ('computer', 1),\n",
              " ('users.', 1),\n",
              " ('', 1),\n",
              " ('At', 1),\n",
              " ('our', 1),\n",
              " ('revised', 1),\n",
              " ('rates', 1),\n",
              " ('of', 1),\n",
              " ('production,', 1),\n",
              " ('we', 1),\n",
              " ('will', 1),\n",
              " ('reach', 1),\n",
              " ('only', 1),\n",
              " ('one-third', 1),\n",
              " ('of', 1),\n",
              " ('that', 1),\n",
              " ('goal', 1),\n",
              " ('by', 1),\n",
              " ('the', 1),\n",
              " ('end', 1),\n",
              " ('of', 1),\n",
              " ('2001,', 1),\n",
              " ('or', 1),\n",
              " ('about', 1),\n",
              " ('3,333', 1),\n",
              " ('Etexts', 1),\n",
              " ('unless', 1),\n",
              " ('we', 1),\n",
              " ('manage', 1),\n",
              " ('to', 1),\n",
              " ('get', 1),\n",
              " ('some', 1),\n",
              " ('real', 1),\n",
              " ('funding;', 1),\n",
              " ('currently', 1),\n",
              " ('our', 1),\n",
              " ('funding', 1),\n",
              " ('is', 1),\n",
              " ('mostly', 1),\n",
              " ('from', 1),\n",
              " ('Michael', 1),\n",
              " (\"Hart's\", 1),\n",
              " ('salary', 1),\n",
              " ('at', 1),\n",
              " ('Carnegie-Mellon', 1),\n",
              " ('University,', 1),\n",
              " ('and', 1),\n",
              " ('an', 1),\n",
              " ('assortment', 1),\n",
              " ('of', 1),\n",
              " ('sporadic', 1),\n",
              " ('gifts;', 1),\n",
              " ('this', 1),\n",
              " ('salary', 1),\n",
              " ('is', 1),\n",
              " ('only', 1),\n",
              " ('good', 1),\n",
              " ('for', 1),\n",
              " ('a', 1),\n",
              " ('few', 1),\n",
              " ('more', 1),\n",
              " ('years,', 1),\n",
              " ('so', 1),\n",
              " ('we', 1),\n",
              " ('are', 1),\n",
              " ('looking', 1),\n",
              " ('for', 1),\n",
              " ('something', 1),\n",
              " ('to', 1),\n",
              " ('replace', 1),\n",
              " ('it,', 1),\n",
              " ('as', 1),\n",
              " ('we', 1),\n",
              " (\"don't\", 1),\n",
              " ('want', 1),\n",
              " ('Project', 1),\n",
              " ('Gutenberg', 1),\n",
              " ('to', 1),\n",
              " ('be', 1),\n",
              " ('so', 1),\n",
              " ('dependent', 1),\n",
              " ('on', 1),\n",
              " ('one', 1),\n",
              " ('person.', 1),\n",
              " ('', 1),\n",
              " ('We', 1),\n",
              " ('need', 1),\n",
              " ('your', 1),\n",
              " ('donations', 1),\n",
              " ('more', 1),\n",
              " ('than', 1),\n",
              " ('ever!', 1),\n",
              " ('', 1),\n",
              " ('', 1),\n",
              " ('All', 1),\n",
              " ('donations', 1),\n",
              " ('should', 1),\n",
              " ('be', 1),\n",
              " ('made', 1),\n",
              " ('to', 1),\n",
              " ('\"Project', 1),\n",
              " ('Gutenberg/CMU\":', 1),\n",
              " ('and', 1),\n",
              " ('are', 1),\n",
              " ('tax', 1),\n",
              " ('deductible', 1),\n",
              " ('to', 1),\n",
              " ('the', 1),\n",
              " ('extent', 1),\n",
              " ('allowable', 1),\n",
              " ('by', 1),\n",
              " ('law.', 1),\n",
              " ('', 1),\n",
              " ('(CMU', 1),\n",
              " ('=', 1),\n",
              " ('Carnegie-', 1),\n",
              " ('Mellon', 1),\n",
              " ('University).', 1),\n",
              " ('', 1),\n",
              " ('For', 1),\n",
              " ('these', 1),\n",
              " ('and', 1),\n",
              " ('other', 1),\n",
              " ('matters,', 1),\n",
              " ('please', 1),\n",
              " ('mail', 1),\n",
              " ('to:', 1),\n",
              " ('', 1),\n",
              " ('Project', 1),\n",
              " ('Gutenberg', 1),\n",
              " ('P.', 1),\n",
              " ('O.', 1),\n",
              " ('Box', 1),\n",
              " ('', 1),\n",
              " ('2782', 1),\n",
              " ('Champaign,', 1),\n",
              " ('IL', 1),\n",
              " ('61825', 1),\n",
              " ('', 1),\n",
              " ('When', 1),\n",
              " ('all', 1),\n",
              " ('other', 1),\n",
              " ('email', 1),\n",
              " ('fails.', 1),\n",
              " ('.', 1),\n",
              " ('.try', 1),\n",
              " ('our', 1),\n",
              " ('Executive', 1),\n",
              " ('Director:', 1),\n",
              " ('Michael', 1),\n",
              " ('S.', 1),\n",
              " ('Hart', 1),\n",
              " ('<hart@pobox.com>', 1),\n",
              " ('hart@pobox.com', 1),\n",
              " ('forwards', 1),\n",
              " ('to', 1),\n",
              " ('hart@prairienet.org', 1),\n",
              " ('and', 1),\n",
              " ('archive.org', 1),\n",
              " ('if', 1),\n",
              " ('your', 1),\n",
              " ('mail', 1),\n",
              " ('bounces', 1),\n",
              " ('from', 1),\n",
              " ('archive.org,', 1),\n",
              " ('I', 1),\n",
              " ('will', 1),\n",
              " ('still', 1),\n",
              " ('see', 1),\n",
              " ('it,', 1),\n",
              " ('if', 1),\n",
              " ('it', 1),\n",
              " ('bounces', 1),\n",
              " ('from', 1),\n",
              " ('prairienet.org,', 1),\n",
              " ('better', 1),\n",
              " ('resend', 1),\n",
              " ('later', 1),\n",
              " ('on.', 1),\n",
              " ('.', 1),\n",
              " ('.', 1),\n",
              " ('.', 1),\n",
              " ('', 1),\n",
              " ('We', 1),\n",
              " ('would', 1),\n",
              " ('prefer', 1),\n",
              " ('to', 1),\n",
              " ('send', 1),\n",
              " ('you', 1),\n",
              " ('this', 1),\n",
              " ('information', 1),\n",
              " ('by', 1),\n",
              " ('email.', 1),\n",
              " ('', 1),\n",
              " ('******', 1),\n",
              " ('', 1),\n",
              " ('To', 1),\n",
              " ('access', 1),\n",
              " ('Project', 1),\n",
              " ('Gutenberg', 1),\n",
              " ('etexts,', 1),\n",
              " ('use', 1),\n",
              " ('any', 1),\n",
              " ('Web', 1),\n",
              " ('browser', 1),\n",
              " ('to', 1),\n",
              " ('view', 1),\n",
              " ('http://promo.net/pg.', 1),\n",
              " ('', 1),\n",
              " ('This', 1),\n",
              " ('site', 1),\n",
              " ('lists', 1),\n",
              " ('Etexts', 1),\n",
              " ('by', 1),\n",
              " ('author', 1),\n",
              " ('and', 1),\n",
              " ('by', 1),\n",
              " ('title,', 1),\n",
              " ('and', 1),\n",
              " ('includes', 1),\n",
              " ('information', 1),\n",
              " ('about', 1),\n",
              " ('how', 1),\n",
              " ('to', 1),\n",
              " ('get', 1),\n",
              " ('involved', 1),\n",
              " ('with', 1),\n",
              " ('Project', 1),\n",
              " ('Gutenberg.', 1),\n",
              " ('', 1),\n",
              " ('You', 1),\n",
              " ('could', 1),\n",
              " ('also', 1),\n",
              " ('download', 1),\n",
              " ('our', 1),\n",
              " ('past', 1),\n",
              " ('Newsletters,', 1),\n",
              " ('or', 1),\n",
              " ('subscribe', 1),\n",
              " ('here.', 1),\n",
              " ('', 1),\n",
              " ('This', 1),\n",
              " ('is', 1),\n",
              " ('one', 1),\n",
              " ('of', 1),\n",
              " ('our', 1),\n",
              " ('major', 1),\n",
              " ('sites,', 1),\n",
              " ('please', 1),\n",
              " ('email', 1),\n",
              " ('hart@pobox.com,', 1),\n",
              " ('for', 1),\n",
              " ('a', 1),\n",
              " ('more', 1),\n",
              " ('complete', 1),\n",
              " ('list', 1),\n",
              " ('of', 1),\n",
              " ('our', 1),\n",
              " ('various', 1),\n",
              " ('sites.', 1),\n",
              " ('', 1),\n",
              " ('To', 1),\n",
              " ('go', 1),\n",
              " ('directly', 1),\n",
              " ('to', 1),\n",
              " ('the', 1),\n",
              " ('etext', 1),\n",
              " ('collections,', 1),\n",
              " ('use', 1),\n",
              " ('FTP', 1),\n",
              " ('or', 1),\n",
              " ('any', 1),\n",
              " ('Web', 1),\n",
              " ('browser', 1),\n",
              " ('to', 1),\n",
              " ('visit', 1),\n",
              " ('a', 1),\n",
              " ('Project', 1),\n",
              " ('Gutenberg', 1),\n",
              " ('mirror', 1),\n",
              " ('(mirror', 1),\n",
              " ('sites', 1),\n",
              " ('are', 1),\n",
              " ('available', 1),\n",
              " ('on', 1),\n",
              " ('7', 1),\n",
              " ('continents;', 1),\n",
              " ('mirrors', 1),\n",
              " ('are', 1),\n",
              " ('listed', 1),\n",
              " ('at', 1),\n",
              " ('http://promo.net/pg).', 1),\n",
              " ('', 1),\n",
              " ('Mac', 1),\n",
              " ('users,', 1),\n",
              " ('do', 1),\n",
              " ('NOT', 1),\n",
              " ('point', 1),\n",
              " ('and', 1),\n",
              " ('click,', 1),\n",
              " ('typing', 1),\n",
              " ('works', 1),\n",
              " ('better.', 1),\n",
              " ('', 1),\n",
              " ('Example', 1),\n",
              " ('FTP', 1),\n",
              " ('session:', 1),\n",
              " ('', 1),\n",
              " ('ftp', 1),\n",
              " ('sunsite.unc.edu', 1),\n",
              " ('login:', 1),\n",
              " ('anonymous', 1),\n",
              " ('password:', 1),\n",
              " ('your@login', 1),\n",
              " ('cd', 1),\n",
              " ('pub/docs/books/gutenberg', 1),\n",
              " ('cd', 1),\n",
              " ('etext90', 1),\n",
              " ('through', 1),\n",
              " ('etext99', 1),\n",
              " ('dir', 1),\n",
              " ('[to', 1),\n",
              " ('see', 1),\n",
              " ('files]', 1),\n",
              " ('get', 1),\n",
              " ('or', 1),\n",
              " ('mget', 1),\n",
              " ('[to', 1),\n",
              " ('get', 1),\n",
              " ('files.', 1),\n",
              " ('.', 1),\n",
              " ('.set', 1),\n",
              " ('bin', 1),\n",
              " ('for', 1),\n",
              " ('zip', 1),\n",
              " ('files]', 1),\n",
              " ('GET', 1),\n",
              " ('GUTINDEX.??', 1),\n",
              " ('', 1),\n",
              " ('[to', 1),\n",
              " ('get', 1),\n",
              " ('a', 1),\n",
              " (\"year's\", 1),\n",
              " ('listing', 1),\n",
              " ('of', 1),\n",
              " ('books,', 1),\n",
              " ('e.g.,', 1),\n",
              " ('GUTINDEX.99]', 1),\n",
              " ('GET', 1),\n",
              " ('GUTINDEX.ALL', 1),\n",
              " ('[to', 1),\n",
              " ('get', 1),\n",
              " ('a', 1),\n",
              " ('listing', 1),\n",
              " ('of', 1),\n",
              " ('ALL', 1),\n",
              " ('books]', 1),\n",
              " ('', 1),\n",
              " ('***', 1),\n",
              " ('', 1),\n",
              " ('**Information', 1),\n",
              " ('prepared', 1),\n",
              " ('by', 1),\n",
              " ('the', 1),\n",
              " ('Project', 1),\n",
              " ('Gutenberg', 1),\n",
              " ('legal', 1),\n",
              " ('advisor**', 1),\n",
              " ('', 1),\n",
              " ('(Three', 1),\n",
              " ('Pages)', 1),\n",
              " ('', 1),\n",
              " ('', 1),\n",
              " ('***START**THE', 1),\n",
              " ('SMALL', 1),\n",
              " ('PRINT!**FOR', 1),\n",
              " ('PUBLIC', 1),\n",
              " ('DOMAIN', 1),\n",
              " ('ETEXTS**START***', 1),\n",
              " ('Why', 1),\n",
              " ('is', 1),\n",
              " ('this', 1),\n",
              " ('\"Small', 1),\n",
              " ('Print!\"', 1),\n",
              " ('statement', 1),\n",
              " ('here?', 1),\n",
              " ('', 1),\n",
              " ('You', 1),\n",
              " ('know:', 1),\n",
              " ('lawyers.', 1),\n",
              " ('They', 1),\n",
              " ('tell', 1),\n",
              " ('us', 1),\n",
              " ('you', 1),\n",
              " ('might', 1),\n",
              " ('sue', 1),\n",
              " ('us', 1),\n",
              " ('if', 1),\n",
              " ('there', 1),\n",
              " ('is', 1),\n",
              " ('something', 1),\n",
              " ('wrong', 1),\n",
              " ('with', 1),\n",
              " ('your', 1),\n",
              " ('copy', 1),\n",
              " ('of', 1),\n",
              " ('this', 1),\n",
              " ('etext,', 1),\n",
              " ('even', 1),\n",
              " ('if', 1),\n",
              " ('you', 1),\n",
              " ('got', 1),\n",
              " ('it', 1),\n",
              " ('for', 1),\n",
              " ('free', 1),\n",
              " ('from', 1),\n",
              " ('someone', 1),\n",
              " ('other', 1),\n",
              " ('than', 1),\n",
              " ('us,', 1),\n",
              " ('and', 1),\n",
              " ('even', 1),\n",
              " ('if', 1),\n",
              " (\"what's\", 1),\n",
              " ('wrong', 1),\n",
              " ('is', 1),\n",
              " ('not', 1),\n",
              " ('our', 1),\n",
              " ('fault.', 1),\n",
              " ('', 1),\n",
              " ('So,', 1),\n",
              " ('among', 1),\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kU5OA9NcWahy"
      },
      "source": [
        "rdd1=rdd.reduceByKey(lambda x,y:x+y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFyzbjtLWoGC",
        "outputId": "71a4061a-e51c-4fa3-ecc8-7a78588521d1"
      },
      "source": [
        "rdd1.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Project', 25),\n",
              " ('Etext', 7),\n",
              " ('of', 14571),\n",
              " (\"Shakespeare's\", 8),\n",
              " ('is', 7459),\n",
              " ('3rd', 1),\n",
              " ('edition', 3),\n",
              " ('these', 1000),\n",
              " ('plays.', 1),\n",
              " ('', 107574),\n",
              " ('index.', 1),\n",
              " ('are', 2777),\n",
              " ('world,', 104),\n",
              " ('sure', 208),\n",
              " ('check', 5),\n",
              " ('copyright', 8),\n",
              " ('country', 3),\n",
              " ('before', 472),\n",
              " ('posting', 3),\n",
              " ('Please', 48),\n",
              " ('take', 934),\n",
              " ('look', 27),\n",
              " ('at', 2074),\n",
              " ('in', 8779),\n",
              " ('this', 4669),\n",
              " ('own', 17),\n",
              " ('an', 1307),\n",
              " ('path', 7),\n",
              " ('open', 86),\n",
              " ('Do', 277),\n",
              " ('remove', 1),\n",
              " ('The', 3321),\n",
              " ('World', 61),\n",
              " ('Free', 12),\n",
              " ('Plain', 1),\n",
              " ('Electronic', 1),\n",
              " ('**Etexts', 1),\n",
              " ('Since', 131),\n",
              " ('1971**', 1),\n",
              " ('Donations*', 1),\n",
              " ('Information', 2),\n",
              " ('Etexts,', 1),\n",
              " ('further', 129),\n",
              " ('below.', 4),\n",
              " ('donations.', 1),\n",
              " ('Shakespeare', 5),\n",
              " ('named', 3),\n",
              " ('00ws110.txt', 1),\n",
              " ('EDITIONS', 1),\n",
              " ('new', 191),\n",
              " ('NUMBER,', 1),\n",
              " ('based', 1),\n",
              " ('LETTER,', 1),\n",
              " ('created', 13),\n",
              " ('multiple', 1),\n",
              " ('Public', 1),\n",
              " ('Domain', 1),\n",
              " ('United', 3),\n",
              " ('Therefore,', 21),\n",
              " ('we', 2284),\n",
              " ('do', 1695),\n",
              " ('books', 3),\n",
              " ('compliance', 1),\n",
              " ('particular', 33),\n",
              " ('now', 1374),\n",
              " ('trying', 1),\n",
              " ('month', 12),\n",
              " ('official', 2),\n",
              " ('note:', 11),\n",
              " ('neither', 85),\n",
              " ('nor', 554),\n",
              " ('contents', 7),\n",
              " ('till', 383),\n",
              " ('midnight', 15),\n",
              " ('last', 170),\n",
              " ('Central', 1),\n",
              " ('Time,', 27),\n",
              " ('stated', 1),\n",
              " ('month.', 2),\n",
              " ('preliminary', 1),\n",
              " ('version', 1),\n",
              " ('may', 1311),\n",
              " ('so.', 70),\n",
              " ('have', 36),\n",
              " ('[xxxxx10x.xxx]', 1),\n",
              " ('sizes', 1),\n",
              " ('week', 2),\n",
              " ('ftp', 2),\n",
              " ('fix', 1),\n",
              " ('failed]', 1),\n",
              " ('size', 5),\n",
              " ('do,', 117),\n",
              " ('but', 3411),\n",
              " ('try', 48),\n",
              " ('more', 1578),\n",
              " ('less.', 1),\n",
              " ('(one', 1),\n",
              " ('produce', 15),\n",
              " ('two', 547),\n",
              " ('work.', 2),\n",
              " ('rather', 261),\n",
              " ('conservative', 1),\n",
              " ('estimate,', 2),\n",
              " ('hours', 4),\n",
              " ('selected,', 1),\n",
              " ('entered,', 1),\n",
              " ('proofread,', 1),\n",
              " ('searched', 1),\n",
              " ('letters', 12),\n",
              " ('etc.', 2),\n",
              " ('projected', 1),\n",
              " ('value', 12),\n",
              " ('nominally', 1),\n",
              " ('estimated', 1),\n",
              " ('year', 2),\n",
              " ('as', 3861),\n",
              " ('thirty-six', 1),\n",
              " ('files', 1),\n",
              " ('month,', 2),\n",
              " ('just', 3),\n",
              " ('population,', 1),\n",
              " ('away', 361),\n",
              " ('Goal', 1),\n",
              " ('Give', 1),\n",
              " ('Away', 92),\n",
              " ('One', 172),\n",
              " ('Files', 4),\n",
              " ('31,', 1),\n",
              " ('=', 2),\n",
              " ('1', 202),\n",
              " ('ten', 101),\n",
              " ('thousand', 287),\n",
              " ('titles', 3),\n",
              " ('readers,', 1),\n",
              " ('only', 20),\n",
              " ('~5%', 1),\n",
              " ('users.', 1),\n",
              " ('At', 203),\n",
              " ('revised', 1),\n",
              " ('rates', 3),\n",
              " ('production,', 1),\n",
              " ('goal', 1),\n",
              " ('end', 177),\n",
              " ('2001,', 1),\n",
              " ('Michael', 11),\n",
              " (\"Hart's\", 1),\n",
              " ('Carnegie-Mellon', 3),\n",
              " ('University,', 1),\n",
              " ('sporadic', 1),\n",
              " ('good', 1984),\n",
              " ('years,', 2),\n",
              " ('looking', 21),\n",
              " ('something', 110),\n",
              " ('replace', 1),\n",
              " ('it,', 623),\n",
              " ('dependent', 1),\n",
              " ('than', 33),\n",
              " ('ever!', 1),\n",
              " ('Gutenberg/CMU\":', 1),\n",
              " ('tax', 3),\n",
              " ('extent', 5),\n",
              " ('(CMU', 1),\n",
              " ('Mellon', 1),\n",
              " ('other', 505),\n",
              " ('matters,', 8),\n",
              " ('P.', 4),\n",
              " ('O.', 2),\n",
              " ('Box', 1),\n",
              " ('Champaign,', 1),\n",
              " ('61825', 1),\n",
              " ('When', 696),\n",
              " ('.', 27),\n",
              " ('Executive', 3),\n",
              " ('Director:', 1),\n",
              " ('Hart', 12),\n",
              " ('hart@pobox.com', 1),\n",
              " ('archive.org', 1),\n",
              " ('bounces', 2),\n",
              " ('archive.org,', 1),\n",
              " ('resend', 1),\n",
              " ('would', 1882),\n",
              " ('send', 210),\n",
              " ('email.', 1),\n",
              " ('******', 1),\n",
              " ('use', 4),\n",
              " ('browser', 2),\n",
              " ('http://promo.net/pg.', 1),\n",
              " ('site', 1),\n",
              " ('title,', 6),\n",
              " ('past', 101),\n",
              " ('Newsletters,', 1),\n",
              " ('subscribe', 9),\n",
              " ('here.', 14),\n",
              " ('major', 1),\n",
              " ('sites,', 1),\n",
              " ('sites.', 1),\n",
              " ('go', 525),\n",
              " ('visit', 43),\n",
              " ('mirror', 1),\n",
              " ('mirrors', 1),\n",
              " ('listed', 1),\n",
              " ('point', 78),\n",
              " ('click,', 1),\n",
              " ('typing', 1),\n",
              " ('Example', 1),\n",
              " ('sunsite.unc.edu', 1),\n",
              " ('login:', 1),\n",
              " ('anonymous', 1),\n",
              " ('cd', 2),\n",
              " ('etext99', 1),\n",
              " ('dir', 1),\n",
              " ('mget', 1),\n",
              " ('zip', 1),\n",
              " ('GET', 2),\n",
              " ('GUTINDEX.??', 1),\n",
              " (\"year's\", 1),\n",
              " ('listing', 2),\n",
              " ('books,', 2),\n",
              " ('***', 3),\n",
              " ('prepared', 8),\n",
              " ('legal', 4),\n",
              " ('advisor**', 1),\n",
              " ('PUBLIC', 2),\n",
              " ('DOMAIN', 2),\n",
              " ('ETEXTS**START***', 1),\n",
              " ('Print!\"', 5),\n",
              " ('statement', 2),\n",
              " ('They', 428),\n",
              " ('tell', 768),\n",
              " ('us', 3),\n",
              " ('there', 984),\n",
              " ('etext,', 6),\n",
              " ('even', 5),\n",
              " ('got', 83),\n",
              " ('free', 111),\n",
              " ('fault.', 5),\n",
              " ('So,', 46),\n",
              " ('things,', 41),\n",
              " ('liability', 2),\n",
              " ('It', 886),\n",
              " ('tells', 13),\n",
              " ('to.', 10),\n",
              " ('*BEFORE!*', 1),\n",
              " ('YOU', 7),\n",
              " ('USE', 1),\n",
              " ('THIS', 2),\n",
              " ('ETEXT', 3),\n",
              " ('using', 2),\n",
              " ('GUTENBERG-tm', 3),\n",
              " ('indicate', 2),\n",
              " ('understand,', 1),\n",
              " ('statement.', 3),\n",
              " ('refund', 3),\n",
              " ('money', 59),\n",
              " ('(if', 32),\n",
              " ('any)', 2),\n",
              " ('paid', 30),\n",
              " ('days', 3),\n",
              " ('person', 55),\n",
              " ('from.', 4),\n",
              " ('medium', 3),\n",
              " ('(such', 2),\n",
              " ('disk),', 1),\n",
              " ('must', 1249),\n",
              " ('request.', 4),\n",
              " ('ABOUT', 1),\n",
              " ('ETEXTS', 1),\n",
              " ('like', 1366),\n",
              " ('tm', 1),\n",
              " ('\"public', 1),\n",
              " ('work', 4),\n",
              " ('Professor', 1),\n",
              " ('University', 2),\n",
              " ('(the', 14),\n",
              " ('Among', 23),\n",
              " ('means', 6),\n",
              " ('no', 2368),\n",
              " ('owns', 1),\n",
              " ('States', 5),\n",
              " ('work,', 4),\n",
              " ('(and', 16),\n",
              " ('you!)', 1),\n",
              " ('paying', 5),\n",
              " ('royalties.', 1),\n",
              " ('Special', 1),\n",
              " ('rules,', 1),\n",
              " ('set', 373),\n",
              " ('below,', 11),\n",
              " (\"Project's\", 2),\n",
              " ('\"PROJECT', 2),\n",
              " ('GUTENBERG\"', 1),\n",
              " ('trademark.', 1),\n",
              " ('efforts', 1),\n",
              " ('identify,', 1),\n",
              " ('transcribe', 1),\n",
              " ('proofread', 1),\n",
              " ('public', 2),\n",
              " ('domain', 2),\n",
              " ('Despite', 2),\n",
              " ('efforts,', 1),\n",
              " ('form', 4),\n",
              " ('inaccurate', 1),\n",
              " ('corrupt', 19),\n",
              " ('transcription', 1),\n",
              " ('errors,', 7),\n",
              " ('infringement,', 1),\n",
              " ('disk', 1),\n",
              " ('virus,', 1),\n",
              " ('damage', 1),\n",
              " ('cannot', 664),\n",
              " ('read', 78),\n",
              " ('WARRANTY;', 1),\n",
              " ('OF', 16),\n",
              " ('DAMAGES', 1),\n",
              " ('But', 2326),\n",
              " ('Replacement', 1),\n",
              " ('etext)', 1),\n",
              " ('damages,', 2),\n",
              " ('NO', 2),\n",
              " ('FOR', 4),\n",
              " ('NEGLIGENCE', 1),\n",
              " ('UNDER', 2),\n",
              " ('STRICT', 1),\n",
              " ('BREACH', 1),\n",
              " ('CONTRACT,', 1),\n",
              " ('INCLUDING', 2),\n",
              " ('BUT', 2),\n",
              " ('TO', 8),\n",
              " ('CONSEQUENTIAL,', 1),\n",
              " ('DAMAGES,', 1),\n",
              " ('GIVE', 1),\n",
              " ('NOTICE', 1),\n",
              " ('discover', 1),\n",
              " ('explanatory', 1),\n",
              " ('note,', 32),\n",
              " ('alternatively', 2),\n",
              " ('give', 7),\n",
              " ('opportunity', 7),\n",
              " ('IS', 1),\n",
              " ('OTHERWISE', 1),\n",
              " ('PROVIDED', 1),\n",
              " ('OTHER', 1),\n",
              " ('KIND,', 1),\n",
              " ('EXPRESS', 1),\n",
              " ('IMPLIED,', 1),\n",
              " ('ARE', 1),\n",
              " ('AS', 1),\n",
              " ('MAY', 2),\n",
              " ('BE', 1),\n",
              " ('MERCHANTABILITY', 1),\n",
              " ('allow', 16),\n",
              " ('disclaimers', 2),\n",
              " ('implied', 1),\n",
              " ('consequential', 1),\n",
              " ('above', 1),\n",
              " ('exclusions', 1),\n",
              " ('rights.', 2),\n",
              " ('INDEMNITY', 1),\n",
              " ('indemnify', 1),\n",
              " ('officers,', 3),\n",
              " ('members', 7),\n",
              " ('liability,', 1),\n",
              " ('arise', 5),\n",
              " ('indirectly', 5),\n",
              " ('following', 19),\n",
              " ('distribution', 2),\n",
              " ('alteration,', 3),\n",
              " ('GUTENBERG-tm\"', 1),\n",
              " ('book', 1),\n",
              " ('delete', 2),\n",
              " ('references', 1),\n",
              " ('Gutenberg,', 1),\n",
              " ('it.', 241),\n",
              " ('remove,', 1),\n",
              " ('however,', 1),\n",
              " ('wish,', 17),\n",
              " ('machine', 1),\n",
              " ('binary,', 1),\n",
              " ('compressed,', 1),\n",
              " ('proprietary', 2),\n",
              " ('form,', 2),\n",
              " ('resulting', 2),\n",
              " ('pro-', 1),\n",
              " ('cessing', 1),\n",
              " ('software,', 2),\n",
              " ('long', 296),\n",
              " ('when', 1140),\n",
              " ('*not*', 1),\n",
              " ('characters', 5),\n",
              " ('although', 34),\n",
              " ('(~),', 1),\n",
              " ('asterisk', 1),\n",
              " ('(*)', 1),\n",
              " ('underline', 1),\n",
              " ('(_)', 1),\n",
              " ('used', 4),\n",
              " ('convey', 1),\n",
              " ('punctuation', 2),\n",
              " ('author,', 1),\n",
              " ('additional', 2),\n",
              " ('expense', 1),\n",
              " ('into', 518),\n",
              " ('ASCII,', 1),\n",
              " ('(as', 139),\n",
              " ('case,', 16),\n",
              " ('instance,', 4),\n",
              " ('processors);', 1),\n",
              " ('provide,', 1),\n",
              " ('provide', 1),\n",
              " ('fee', 5),\n",
              " ('form).', 1),\n",
              " ('derive', 2),\n",
              " ('already', 66),\n",
              " ('calculate', 2),\n",
              " ('taxes.', 1),\n",
              " ('due.', 2),\n",
              " ('University\"', 1),\n",
              " ('60', 1),\n",
              " ('prepare', 41),\n",
              " ('return.', 1),\n",
              " ('WHAT', 1),\n",
              " ('*WANT*', 1),\n",
              " ('SEND', 1),\n",
              " (\"DON'T\", 1),\n",
              " ('gratefully', 1),\n",
              " ('accepts', 3),\n",
              " ('money,', 24),\n",
              " ('scanning', 2),\n",
              " ('licenses,', 1),\n",
              " ('think', 33),\n",
              " ('of.', 21),\n",
              " ('*END*THE', 1),\n",
              " ('PRINT!', 1),\n",
              " ('ETEXTS*Ver.04.29.93*END*', 1),\n",
              " ('notes', 12),\n",
              " ('spelling', 5),\n",
              " ('errors', 7),\n",
              " ('introduced', 1),\n",
              " ('printers', 2),\n",
              " ('corrected,', 1),\n",
              " ('presented', 8),\n",
              " ('Barnardo.', 2),\n",
              " ('there?', 96),\n",
              " ('Fran.', 32),\n",
              " ('Stand', 87),\n",
              " ('Long', 36),\n",
              " ('liue', 302),\n",
              " ('understand', 2),\n",
              " ('ran', 17),\n",
              " ('out', 925),\n",
              " ('certain', 3),\n",
              " ('packed', 2),\n",
              " ('\"cliche\".', 1),\n",
              " ('meaning', 37),\n",
              " ('term', 1),\n",
              " ('cliche.', 1),\n",
              " ('.and', 3),\n",
              " ('unwilling', 1),\n",
              " ('unpack', 1),\n",
              " ('thus', 407),\n",
              " ('substitutions', 1),\n",
              " ('very', 608),\n",
              " ('.such', 1),\n",
              " ('v,', 1),\n",
              " ('u,', 1),\n",
              " ('wonder', 69),\n",
              " ('why', 293),\n",
              " ('cliche', 1),\n",
              " ('\"v\"\\'s.', 1),\n",
              " ('.possibly', 1),\n",
              " ('was', 1856),\n",
              " ('common', 120),\n",
              " ('print', 10),\n",
              " ('quite', 56),\n",
              " (\"didn't\", 1),\n",
              " ('text,', 2),\n",
              " ('places,', 10),\n",
              " ('\"scholars\"', 1),\n",
              " ('extreme', 9),\n",
              " ('attachment', 1),\n",
              " ('them', 1271),\n",
              " ('high', 172),\n",
              " ('Shakespeare.', 3),\n",
              " ('father', 123),\n",
              " ('Cambridge', 3),\n",
              " ('several', 2),\n",
              " ('months', 13),\n",
              " ('glass', 1),\n",
              " ('room', 2),\n",
              " ('purpose.', 14),\n",
              " ('best', 342),\n",
              " ('knowledge', 47),\n",
              " ('he', 4051),\n",
              " ('.in', 1),\n",
              " ('determined', 5),\n",
              " ('changes,', 2),\n",
              " ('likely', 19),\n",
              " ('though', 356),\n",
              " ('signing', 1),\n",
              " ('his', 5783),\n",
              " ('name', 345),\n",
              " ('different', 10),\n",
              " ('spellings.', 1),\n",
              " ('account', 23),\n",
              " ('comments', 2),\n",
              " ('below', 21),\n",
              " ('volunteer', 1),\n",
              " ('\"not\"', 1),\n",
              " ('errors.', 2),\n",
              " ('.with', 1),\n",
              " ('.we', 1),\n",
              " ('changed', 5),\n",
              " (\"Scanner's\", 1),\n",
              " ('What', 1749),\n",
              " ('close', 67),\n",
              " ('Pericles,', 1),\n",
              " ('Prince', 219),\n",
              " ('Tyre', 2),\n",
              " (\"wasn't\", 2),\n",
              " ('poems', 1),\n",
              " ('elongated', 1),\n",
              " (\"S's\", 1),\n",
              " ('spelling,', 1),\n",
              " ('possible', 30),\n",
              " ('put', 420),\n",
              " ('dictionary', 1),\n",
              " ('spellings', 2),\n",
              " ('Geneva', 1),\n",
              " ('Bible', 1),\n",
              " ('unified', 1),\n",
              " ('them.', 111),\n",
              " ('brackets', 2),\n",
              " ('[]', 1),\n",
              " ('added.', 1),\n",
              " ('everything', 1),\n",
              " ('Another', 25),\n",
              " ('differences', 5),\n",
              " ('above)', 1),\n",
              " ('editions.', 1),\n",
              " ('due', 48),\n",
              " (\"printer's\", 1),\n",
              " ('habit', 14),\n",
              " ('type', 3),\n",
              " ('proofing', 1),\n",
              " ('continuing', 1),\n",
              " ('printing', 2),\n",
              " ('run.', 1),\n",
              " ('proof', 1),\n",
              " ('run', 90),\n",
              " ('way', 330),\n",
              " ('composite', 1),\n",
              " (\"editions'\", 1),\n",
              " ('pages.', 1),\n",
              " ('feel', 1),\n",
              " ('make', 1362),\n",
              " ('possible.', 3),\n",
              " ('right', 202),\n",
              " ('davidr@inconnect.com.', 1),\n",
              " ('thou', 4020),\n",
              " ('put,', 1),\n",
              " ('gentle', 287),\n",
              " ('cut:', 4),\n",
              " ('dravvne', 1),\n",
              " ('vvit', 1),\n",
              " ('Hisface;', 1),\n",
              " ('Print', 2),\n",
              " ('vvould', 1),\n",
              " ('surpasse', 1),\n",
              " ('All,', 6),\n",
              " ('vvas', 1),\n",
              " ('frasse.', 1),\n",
              " ('cannot,', 21),\n",
              " ('Reader,', 1),\n",
              " ('looke', 473),\n",
              " ('Not', 423),\n",
              " ('picture,', 4),\n",
              " ('SHAKESPEARES', 1),\n",
              " ('Original', 1),\n",
              " ('Copies', 3),\n",
              " ('Iaggard,', 1),\n",
              " ('Ed,', 1),\n",
              " ('Bount.', 1),\n",
              " ('1623', 1),\n",
              " ('MOST', 1),\n",
              " ('INCOMPARABLE', 1),\n",
              " ('WILLIAM', 1),\n",
              " ('Pembroke,&c;.', 1),\n",
              " ('Lord', 1199),\n",
              " ('Chamberlaine', 5),\n",
              " ('Majesty.', 1),\n",
              " ('N', 5),\n",
              " ('Montgomery,&c;.', 1),\n",
              " ('Order', 20),\n",
              " ('Garter,', 5),\n",
              " ('singular', 6),\n",
              " ('L', 10),\n",
              " ('O', 1101),\n",
              " ('R', 7),\n",
              " ('S', 10),\n",
              " ('Honourable,', 6),\n",
              " ('Whilst', 10),\n",
              " ('favors', 1),\n",
              " ('upon', 3),\n",
              " ('ill', 154),\n",
              " ('mingle', 11),\n",
              " ('diverse', 2),\n",
              " ('things', 224),\n",
              " ('successe.', 4),\n",
              " ('valew', 5),\n",
              " ('H.H.', 3),\n",
              " ('know', 1305),\n",
              " ('descend', 8),\n",
              " ('trifles:', 3),\n",
              " ('trifles,', 3),\n",
              " ('selves', 1),\n",
              " ('Dedication.', 1),\n",
              " (\"pleas'd\", 51),\n",
              " ('trifles', 6),\n",
              " ('heeretofore;', 1),\n",
              " ('both', 374),\n",
              " ('them,', 318),\n",
              " ('out-living', 1),\n",
              " ('some,', 13),\n",
              " ('exequutor', 1),\n",
              " ('toward', 85),\n",
              " ('parent.', 1),\n",
              " ('Booke', 24),\n",
              " ('finde', 373),\n",
              " ('both.', 21),\n",
              " ('likings', 3),\n",
              " ('acted,', 3),\n",
              " (\"ask'd\", 15),\n",
              " ('yours.', 19),\n",
              " ('dead,', 144),\n",
              " ('procure', 11),\n",
              " ('Orphanes,', 1),\n",
              " ('Guardians;', 1),\n",
              " ('ambition', 4),\n",
              " ('selfe-profit,', 1),\n",
              " ('fame:', 4),\n",
              " ('keepe', 365),\n",
              " ('Fellow', 52),\n",
              " ('alive,', 1),\n",
              " ('K', 4),\n",
              " ('noble', 115),\n",
              " ('patronage.', 1),\n",
              " ('Wherein,', 2),\n",
              " ('kind', 48),\n",
              " ('religious', 4),\n",
              " ('addresse;', 1),\n",
              " ('care,', 30),\n",
              " ('perfection.', 3),\n",
              " ('abilities', 4),\n",
              " ('Lords.', 47),\n",
              " ('beyond', 39),\n",
              " ('Country', 40),\n",
              " ('foorth', 12),\n",
              " ('milke,', 7),\n",
              " ('creame,', 1),\n",
              " ('(we', 2),\n",
              " ('heard)', 1),\n",
              " ('incense,', 1),\n",
              " ('obtained', 2),\n",
              " ('requests', 10),\n",
              " ('leavened', 1),\n",
              " ('Cake.', 1),\n",
              " ('fault', 76),\n",
              " ('approach', 32),\n",
              " ('Gods,', 63),\n",
              " ('could:', 4),\n",
              " ('And', 7029),\n",
              " ('meanest,', 1),\n",
              " ('precious,', 4),\n",
              " ('dedicated', 3),\n",
              " ('therefore,', 23),\n",
              " ('humbly', 48),\n",
              " ('Shakespeare;', 1),\n",
              " ('delight', 34),\n",
              " ('ever', 1),\n",
              " ('committed,', 7),\n",
              " ('payre', 14),\n",
              " ('shew', 257),\n",
              " ('gratitude', 3),\n",
              " ('bounden,', 1),\n",
              " ('HEMINGE.', 1),\n",
              " ('CONDELL.', 1),\n",
              " ('able,', 3),\n",
              " (\"number'd.\", 1),\n",
              " ('weighd.', 1),\n",
              " ('depends', 9),\n",
              " ('capacities', 2),\n",
              " ('alone,', 67),\n",
              " ('!', 10),\n",
              " ('publique,', 2),\n",
              " ('stand', 360),\n",
              " ('priviledges', 1),\n",
              " ('wee', 218),\n",
              " ('read,', 19),\n",
              " ('censure.', 2),\n",
              " ('That', 2608),\n",
              " ('doth', 705),\n",
              " ('commend', 55),\n",
              " ('Booke,', 12),\n",
              " ('saies.', 1),\n",
              " ('odde', 23),\n",
              " ('braines', 13),\n",
              " ('wisedomes,', 1),\n",
              " ('spare', 49),\n",
              " ('not.', 73),\n",
              " ('worth,', 27),\n",
              " ('worth', 114),\n",
              " ('higher,', 4),\n",
              " ('rates,', 3),\n",
              " ('welcome.', 21),\n",
              " ('Buy.', 2),\n",
              " ('Jacke', 1),\n",
              " ('go.', 23),\n",
              " ('wit,', 57),\n",
              " ('Playes', 4),\n",
              " ('dailie,', 1),\n",
              " ('alreadie,', 8),\n",
              " ('stood', 64),\n",
              " (';', 4),\n",
              " ('quitted', 1),\n",
              " ('Court,', 72),\n",
              " (\"purchas'd\", 5),\n",
              " ('Letters', 79),\n",
              " ('commendation.', 2),\n",
              " ('bene', 65),\n",
              " ('wished,', 1),\n",
              " (\"liv'd\", 1),\n",
              " ('overseen', 1),\n",
              " ('writings', 2),\n",
              " (\"ordain'd\", 5),\n",
              " ('right,', 56),\n",
              " ('pray', 486),\n",
              " (\"publish'd\", 5),\n",
              " ('where', 615),\n",
              " (\"abus'd\", 14),\n",
              " ('stolne,', 6),\n",
              " ('surreptitious', 1),\n",
              " ('deformed', 9),\n",
              " ('frauds', 1),\n",
              " ('stealthes', 1),\n",
              " ('injurious', 1),\n",
              " (\"offer'd\", 19),\n",
              " (\"cur'd,\", 2),\n",
              " ('perfect', 43),\n",
              " ('rest,', 81),\n",
              " ('absolute', 25),\n",
              " ('imitator', 1),\n",
              " ('expresser', 1),\n",
              " ('mind', 35),\n",
              " ('together:', 30),\n",
              " ('thought,', 47),\n",
              " ('uttered', 1),\n",
              " ('easinesse,', 1),\n",
              " ('scarse', 32),\n",
              " ('blot', 11),\n",
              " ('province,', 1),\n",
              " ('gather', 20),\n",
              " ('works,', 1),\n",
              " ('praise', 88),\n",
              " ('yours', 104),\n",
              " ('reade', 58),\n",
              " ('divers', 1),\n",
              " ('enough,', 66),\n",
              " ('draw,', 6),\n",
              " ('lie', 38),\n",
              " ('hid,', 8),\n",
              " ('lost.', 13),\n",
              " ('Reade', 8),\n",
              " ('againe,', 231),\n",
              " ('surely', 30),\n",
              " ('leave', 1),\n",
              " ('need,', 12),\n",
              " ('selves,', 1),\n",
              " ('others.', 33),\n",
              " ('Heminge.', 1),\n",
              " ('Henrie', 18),\n",
              " ('Condell.', 2),\n",
              " ('CATALOGVE', 1),\n",
              " ('Historie,', 2),\n",
              " ('Tragedies', 2),\n",
              " ('Two', 48),\n",
              " ('Measure.', 2),\n",
              " ('Errours.', 1),\n",
              " ('Much', 39),\n",
              " ('adoo', 2),\n",
              " ('Nothing', 83),\n",
              " ('Labour', 5),\n",
              " ('Nights', 17),\n",
              " ('Dreame.', 2),\n",
              " ('Merchant', 18),\n",
              " ('Venice.', 8),\n",
              " ('well,', 295),\n",
              " ('will.', 44),\n",
              " ('Tale.', 5),\n",
              " ('Life', 77),\n",
              " ('second.', 1),\n",
              " ('fourth.', 2),\n",
              " ('Second', 11),\n",
              " ('K.', 8),\n",
              " ('Fift.', 4),\n",
              " ('Sixt.', 4),\n",
              " ('TRAGEDIES.', 1),\n",
              " ('Tragedy', 6),\n",
              " ('Coriolanus.', 10),\n",
              " ('Titus', 63),\n",
              " ('Andronicus.', 6),\n",
              " ('Timon', 44),\n",
              " ('Hamlet.', 22),\n",
              " ('Lear.', 174),\n",
              " ('Anthony', 77),\n",
              " ('Britaine.', 3),\n",
              " ('W', 2),\n",
              " ('draw', 150),\n",
              " ('envy', 1),\n",
              " ('thy', 3488),\n",
              " ('ample', 13),\n",
              " ('confesse', 83),\n",
              " ('such,', 29),\n",
              " ('Muse,', 1),\n",
              " ('much.', 15),\n",
              " (\"men's\", 1),\n",
              " ('suffrage.', 1),\n",
              " ('wayes', 22),\n",
              " ('paths', 3),\n",
              " ('praise;', 1),\n",
              " ('light,', 48),\n",
              " ('sounds', 21),\n",
              " (\"eccho's\", 1),\n",
              " ('right;', 5),\n",
              " ('Or', 638),\n",
              " ('blinde', 31),\n",
              " (\"ne're\", 105),\n",
              " ('truth,', 75),\n",
              " ('urgeth', 1),\n",
              " ('chance;', 2),\n",
              " ('crafty', 5),\n",
              " ('praise,', 25),\n",
              " ('thine', 295),\n",
              " ('These', 203),\n",
              " ('are,', 83),\n",
              " ('infamous', 1),\n",
              " ('Whore,', 7),\n",
              " ('Should', 134),\n",
              " ('Matron.', 1),\n",
              " ('hurt', 66),\n",
              " ('her', 2759),\n",
              " ('more?', 22),\n",
              " ('proofe', 42),\n",
              " ('against', 425),\n",
              " ('indeed', 115),\n",
              " ('Above', 1),\n",
              " ('need.', 4),\n",
              " ('begin.', 7),\n",
              " ('Soule', 75),\n",
              " ('Age', 33),\n",
              " ('applause', 5),\n",
              " ('rise;', 1),\n",
              " ('lodge', 16),\n",
              " ('Spenser,', 1),\n",
              " ('bid', 273),\n",
              " ('Beaumont', 2),\n",
              " ('lye', 142),\n",
              " ('roome', 21),\n",
              " ('Thou', 789),\n",
              " ('tombe,', 3),\n",
              " ('live,', 2),\n",
              " ('wits', 42),\n",
              " ('braine', 19),\n",
              " ('meane', 223),\n",
              " ('thought', 271),\n",
              " ('judgement', 1),\n",
              " ('yeeres,', 22),\n",
              " ('commit', 27),\n",
              " ('peeres,', 1),\n",
              " ('tell,', 23),\n",
              " ('dist', 1),\n",
              " ('Marlowes', 1),\n",
              " ('mighty', 51),\n",
              " ('line.', 2),\n",
              " ('lesse', 151),\n",
              " ('Greeke,', 3),\n",
              " ('honour', 64),\n",
              " ('thee,', 531),\n",
              " ('call', 391),\n",
              " (\"thund'ring\", 1),\n",
              " ('�schilus,', 1),\n",
              " ('vs,', 266),\n",
              " ('Accius,', 1),\n",
              " ('Cordova', 1),\n",
              " ('tread,', 6),\n",
              " ('shake', 77),\n",
              " ('stage', 7),\n",
              " ('on,', 170),\n",
              " ('Of', 864),\n",
              " ('Triumph,', 4),\n",
              " ('Britaine,', 16),\n",
              " ('hast', 526),\n",
              " ('age,', 40),\n",
              " ('Apollo', 11),\n",
              " ('came', 253),\n",
              " ('eares,', 42),\n",
              " ('charme', 17),\n",
              " ('Nature', 133),\n",
              " ('designes,', 5),\n",
              " ('dressing', 1),\n",
              " ('Which', 777),\n",
              " ('spun,', 1),\n",
              " ('woven', 1),\n",
              " ('vouchsafe', 33),\n",
              " ('merry', 71),\n",
              " ('tart', 2),\n",
              " ('Aristophanes,', 1),\n",
              " ('Neat', 1),\n",
              " ('Art,', 20),\n",
              " ('part;', 5),\n",
              " ('Poets', 8),\n",
              " ('matter,', 59),\n",
              " ('Art', 105),\n",
              " ('he,', 108),\n",
              " ('living', 1),\n",
              " ('line,', 4),\n",
              " ('sweat,', 4),\n",
              " ('(Such', 3),\n",
              " ('Upon', 2),\n",
              " ('thinkes', 121),\n",
              " ('frame;', 1),\n",
              " ('scorne,', 12),\n",
              " (\"Poet's\", 1),\n",
              " ('thou.', 7),\n",
              " ('Lives', 1),\n",
              " ('issue,', 7),\n",
              " ('race', 9),\n",
              " ('Shakespeares', 2),\n",
              " ('shines', 24),\n",
              " ('seemes', 89),\n",
              " ('eyes', 263),\n",
              " ('Ignorance.', 2),\n",
              " ('swan', 1),\n",
              " ('fight', 129),\n",
              " ('yet', 988),\n",
              " ('flights', 3),\n",
              " ('Thames,', 3),\n",
              " ('stay,', 54),\n",
              " ('Constellation', 1),\n",
              " ('rage,', 27),\n",
              " ('drooping', 9),\n",
              " ('Stage;', 1),\n",
              " ('flight', 25),\n",
              " (\"mourn'd\", 6),\n",
              " ('Volumes', 2),\n",
              " ('J', 1),\n",
              " ('Scenicke', 1),\n",
              " ('Poet,', 7),\n",
              " ('clapt,', 1),\n",
              " ('done,', 175),\n",
              " ('Globe', 5),\n",
              " (\"heav'n\", 1),\n",
              " ('earth', 87),\n",
              " ('ring.', 3),\n",
              " ('veine,', 2),\n",
              " ('Thespian', 1),\n",
              " ('Spring,', 14),\n",
              " ('teares,', 63),\n",
              " ('Phoebus', 13),\n",
              " ('rayes', 1),\n",
              " (\"crown'd\", 24),\n",
              " ('Poet', 10),\n",
              " ('grave', 1),\n",
              " ('(Deaths', 1),\n",
              " ('Nuncius', 1),\n",
              " ('is,', 273),\n",
              " ('line', 11),\n",
              " ('soone', 109),\n",
              " ('about,', 32),\n",
              " ('never', 2),\n",
              " ('out.', 42),\n",
              " ('E.', 4),\n",
              " ('Shake-speare,', 2),\n",
              " ('length', 24),\n",
              " ('pious', 6),\n",
              " ('world', 259),\n",
              " ('Workes', 3),\n",
              " ('stone', 15),\n",
              " ('rent,', 2),\n",
              " ('Ages:', 1),\n",
              " ('prodegie', 1),\n",
              " ('Shake-speares;', 1),\n",
              " ('Line,', 9),\n",
              " ('Fire,', 15),\n",
              " ('cankring', 1),\n",
              " ('wit-fraught', 1),\n",
              " ('once', 257),\n",
              " (\"e're\", 10),\n",
              " ('mist)', 1),\n",
              " ('sped', 7),\n",
              " ('(Imposible)', 1),\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DdosbisX-a1",
        "outputId": "00418193-52e7-40db-f37c-0a4ca0eb342c"
      },
      "source": [
        "type(rdd1.collect())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyNl4_UFYHz_"
      },
      "source": [
        "df1 = spark.createDataFrame(rdd1).toDF(\"key\",\"value\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AlubbktYQwF",
        "outputId": "7e2291ca-4900-458a-d3a3-e95e1df228ae"
      },
      "source": [
        "df1.show(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+------+\n",
            "|          key| value|\n",
            "+-------------+------+\n",
            "|      Project|    25|\n",
            "|        Etext|     7|\n",
            "|           of| 14571|\n",
            "|Shakespeare's|     8|\n",
            "|           is|  7459|\n",
            "|          3rd|     1|\n",
            "|      edition|     3|\n",
            "|        these|  1000|\n",
            "|       plays.|     1|\n",
            "|             |107574|\n",
            "+-------------+------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12zq2pjbgXzw",
        "outputId": "3b590514-0415-439b-8c8c-21a24ae7a420"
      },
      "source": [
        "df1.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- key: string (nullable = true)\n",
            " |-- value: long (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n43I_VtpYYvV",
        "outputId": "0a908e44-7283-4428-d41d-520c94a1ecf2"
      },
      "source": [
        "df1.filter(df1.value>100).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+\n",
            "|    key| value|\n",
            "+-------+------+\n",
            "|     of| 14571|\n",
            "|     is|  7459|\n",
            "|  these|  1000|\n",
            "|       |107574|\n",
            "|    are|  2777|\n",
            "| world,|   104|\n",
            "|   sure|   208|\n",
            "| before|   472|\n",
            "|   take|   934|\n",
            "|     at|  2074|\n",
            "|     in|  8779|\n",
            "|   this|  4669|\n",
            "|     an|  1307|\n",
            "|     Do|   277|\n",
            "|    The|  3321|\n",
            "|  Since|   131|\n",
            "|further|   129|\n",
            "|    new|   191|\n",
            "|     we|  2284|\n",
            "|     do|  1695|\n",
            "+-------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgOBN6hkdEkR",
        "outputId": "cb42dc18-a701-4237-c14f-ab1dbfda65a0"
      },
      "source": [
        "df1.filter(df1.value>100).orderBy(df1.value.desc()).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+------+\n",
            "| key| value|\n",
            "+----+------+\n",
            "|    |107574|\n",
            "| the| 21652|\n",
            "|   I| 19071|\n",
            "| and| 16624|\n",
            "|  to| 14978|\n",
            "|  of| 14571|\n",
            "|   a| 12121|\n",
            "|  my| 10465|\n",
            "| you|  9838|\n",
            "|  in|  8779|\n",
            "|  is|  7459|\n",
            "|that|  7179|\n",
            "| And|  7029|\n",
            "| not|  6761|\n",
            "|with|  6217|\n",
            "|your|  6186|\n",
            "| his|  5783|\n",
            "|  be|  5454|\n",
            "| for|  5372|\n",
            "|  it|  5329|\n",
            "+----+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4hFNIMWbyS6",
        "outputId": "14e8ccdf-e780-4602-9775-ed39e7ce55fb"
      },
      "source": [
        "df1.filter(df1.value<30).orderBy(df1.value.asc()).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----+\n",
            "|        key|value|\n",
            "+-----------+-----+\n",
            "|        3rd|    1|\n",
            "|     plays.|    1|\n",
            "|     index.|    1|\n",
            "|     remove|    1|\n",
            "|      Plain|    1|\n",
            "| Electronic|    1|\n",
            "|   **Etexts|    1|\n",
            "|     1971**|    1|\n",
            "| Donations*|    1|\n",
            "|    Etexts,|    1|\n",
            "| donations.|    1|\n",
            "|00ws110.txt|    1|\n",
            "|   EDITIONS|    1|\n",
            "|    NUMBER,|    1|\n",
            "|      based|    1|\n",
            "|    LETTER,|    1|\n",
            "|   multiple|    1|\n",
            "|     Public|    1|\n",
            "|     Domain|    1|\n",
            "| compliance|    1|\n",
            "+-----------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCN7yoQ6cyJn",
        "outputId": "30719cbc-1762-4209-d592-fc80819a7933"
      },
      "source": [
        "df1.orderBy(df1.value.desc()).show(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+\n",
            "|key| value|\n",
            "+---+------+\n",
            "|   |107574|\n",
            "+---+------+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14bLxv7XeDY0",
        "outputId": "06ee53b9-3d40-4d37-9bed-91d0e7d4e9b8"
      },
      "source": [
        "df1.orderBy(df1.value.asc()).show(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+\n",
            "|    key|value|\n",
            "+-------+-----+\n",
            "|files!!|    1|\n",
            "+-------+-----+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvYsxj-EeGhr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}